# Fault Tolerance, Consensus, and Mutual Exclusion

To make a single processor more resilient to failure, we can run multiple processors at the same time, and have them execute the same sequence of actions. If one of them fails/crashes, another one of the processors can take over. This is the fundamental principle of fault tolerance. How do we get processors to execute a consistent sequence of actions, though?

If a processor P wants to execute an action locally, it's clear that it can't just go ahead and do it immediately, because another processor Q might also make the same decision at the same time with a conflicting action. So, a processor needs to be sure that others will not execute a conflicting action at a particular slot in the action sequence. So, before executing an action, a processor must do something to ensure this. Thus, the execution of an action becomes a multi-phase process. First, a processor says "I want to execute action A1", and it puts the action into a "pending" state locally, which just means that it is currently trying to get this action executed. It then needs to tell all other processors that it wants to execute A1 and needs them to respond saying "OK, A1 sounds good at slot 1, I will execute that action and no others". Once it hears back from everyone (including itself), it should be able to go ahead and execute (commit) the action safely. This sounds reasonable, but there is an issue with this basic protocol. If there are conflicting proposals, it is possible that the system gets stuck indefinitely. If two processors start proposing conflicting actions around the same time, it's possible that half the processors accept one action and the other half accept the other one. If processors are never allowed to accept new proposals, then neither of the two pending actions will ever be executed and the system will come to a halt.

To solve this liveness problem, it is clear that processors must be able to accept new proposals, even if they've already accepted one previously. How can this be done safely, though? We already said that a processor responds to a proposal with a message saying "I agree with the action you sent me, and I won't execute any other conflicting action." If a processor is allowed to accept a new proposal in the future, though, wouldn't this violate this rule? If we want to maintain the rule that once an action is accepted on all nodes it can be executed, then we need to have some additional way of ensuring that actions accepted on all nodes don't get overwritten by new proposals. In other words, once an action is accepted on all nodes, it can be considered "committed", and proposals that start "later" should never be able to change which action was chosen. So, we can have processors go through an additional phase before trying to get an action accepted. They should first try to learn if any previously proposed actions were already committed, because, in that case, they should be disallowed from proposing actions, since they would potentially overwrite an already committed action. We could call this the "get permission" phase.

It is tricky to execute the "get permission" phase correctly, though, since even if you just learn about previously accepted proposals, this doesn't guarantee you won't overwrite an agreed upon proposal. For example, you may query every other node and see that they have not accepted any proposal yet, but then, right before you start proposing your own proposal, P2, they go ahead and all accept P1. You would then run the risk of overwriting a fully accepted proposal. Recall that if any proposal P1 has been fully accepted, then we can never overwrite it in the future. In other words, we should never be allowed to send out a proposal to a node that would be accepted and conflicts with an already agreed upon proposal. But we also face the problem of how to predict future acceptances after you go around and ask nodes during the "get permission" phase. Fundamentally, there's no way to accurately predict future actions. Instead of predicting future actions, you can constrain the possible future actions. When you go around and ask nodes for permission, you can (1) ask them for any previous proposals and (2) require them to promise that they won't accept any more proposals of a certain type. You could require them to not accept any more proposals of any type, but that would get us back to the liveness problem we faced before i.e. a node always needs to be able to accept new proposals of some sort, at least. Instead of telling the node it can't accept any new proposals, you tell it to reject any proposals less than your current proposal, which is possible if we totally order all proposals. In that case, when you hear back, you have now extracted a promise that all nodes will never accept proposals less than your own. They may accept proposals higher than your own, but if some of them already accepted higher proposals by the time you went around asking for final acceptances, you would be getting rejected, by the rules we just established. In essence, you have laid claim to a certain "epoch"/"ballot" of the algorithm, and said that everyone in earlier ballots is illegitimate, though everyone in later ballots does still have the power to override you. There is the additional restriction, as we noted, that you may be required to propose an action that was already accepted in previous ballots, to ensure the protocol's safety. If none was previously accepted, though, then you are free to propose whatever you want.

In some sense, it feels like the protocol takes advantage of "cooperation" between nodes. If one node fails or is unable to successfully complete its entire proposal, then another node can take over and continue where it left off, in a higher ballot.



- Can a node try to take out a "lock" for its proposal before sending out proposal requests? i.e. a lock being held on a particular processor means that processor will only accept proposals from the processor that holds the lock. Locks seems to suffer from the same liveness issues i.e. what do you do if a node has partially or fully acquired a lock and then fails? Seems to get you right back to the original problem.
- Totally order all proposals. Require that a node goes through a "get permission" phase before starting to propose where it both (1) learns of any proposals that are already agreed upon or may be agreed upon in the future and (2) prevent nodes from accepting any earlier proposals.
- In Paxos, there's nothing fundamental about making sure a majority have accepted a proposal. If, after the "permission" gathering phase, you just write down an acceptance on your own local storage, that would be OK, as long as future notes going through permission gathering phase contact *all* nodes first. This, of course, is a perfectly functional protocol except that you lose out on fault tolerance completely, because of the need to contact all nodes. Instead, if you start replicating the acceptance information to multiple nodes, then it allows future proposers to contact only a subset of all nodes, giving you some fault tolerance. For example, replicating to 2 acceptors allows you to tolerate 1 fault. Is this why we view acceptors as the "stable storage" of the protocol? By making them redundant, we allow future proposers to make progress by only contacing a subset of the acceptor nodes.

### Paxos Protocol Iterations, Strawmen

1. Nodes immediately execute an action when they want. Trivially leads to conflict between two nodes that do this concurrently.
2. Before executing actions immediately, nodes send out requests to others, letting them know they want execute a particular action. Once it receives acks from all nodes, it goes ahead and executes. If nodes accept the first proposal they hear about and don't change, there are liveness problems with this approach, since what if two nodes start proposing around the same time and neither garners votes of everyone. Protocol gets stuck. So, we need some way of allowing nodes to accept new proposals even if they've already accepted old ones. But how to do it safely?

## Mutual Exclusion

- Can mutual exclusion and consensus be viewed as roughly equivalent problems? If a process P has entered a critical section, is this equivalent to saying that all processes have *agreed* on who owns the critical section? If one processor *disagreed*, this would violate mutual exclusion i.e. they would also try to enter the critical section. If we use a lock primitive (i.e. mutex), then the notion of "agreement" seems trivial i.e. with shared memory there is only one location that stores the current critical section owner, and all threads must check that value. What if we view a shared memory write from a message passing perspective, though? For example, if a process P atomically writes to a register that records the state of a lock (i.e. "locked" or "unlocked"), it can be viewed as P messaging every other process saying "I have the lock". The shared memory model is analogous to a process writing a value to a remote buffer i.e. after a message went through the network. If we view locks from that perspective, perhaps we can implement a distributed mutual exclusion primitive by broadcasting a message to all other nodes saying "I want to acquire the lock". In a message passing system, it becomes possible for those messages to reach different nodes at different times, though, whereas writing to a shared memory location is like messaging all other nodes atomically. If there are processes that conflict in their attempt to acquire the lock i.e. access to the critical section, there needs to be some resolution process. If processes don't fail, it would seem reasonable for processes to backoff and try again if their lock attempt failed i.e. if they didn't receive affirmation from all other processes. If a process can fail, though, there is no way for them to abort an in-progress request for the lock.
- Use of locks always allows the possibility that a system will stall, if processes may halt inside their critical section. **Lock freedom** denotes an algorithm that allows system wide progress, but doesn't prevent thread starvation. A stronger condition, **wait freedom**, guarantees the system is not stalled by a single process, and also ensures per thread progress i.e. all threads trying to gain access to a critical section eventually get in, or something like that. Think about distributed consensus algorithms and how they approach wait freedom. In Paxos, for example, if a certain node is trying to get a proposal passed but halts in the middle (i.e. before messaging enough nodes), the protocol allows other nodes to pick up where it left off. The system is not stalled. In short, there are ways to still guarantee mutual exclusion without giving up the liveness properties that you naturally sacrifice when using plain old locks.
- What does a distributed implementation of the bakery algorithm look like? Similarly, what does a local (shared memory) implementation of Paxos look like?
- If you want to build a wait-free algorithm in an asynchronous system model, it would seem that you can *never* be required to wait for any process, since it might always fail/halt indefinitely. You need to always be able to move on without getting hung up on one process' inability to make progress.










