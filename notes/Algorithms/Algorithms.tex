\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{verbatim}
\usepackage{enumerate}
\usepackage{fancyvrb}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes,snakes}
\usepackage[english]{babel}

\geometry{legalpaper, margin=1.5in}

\author{William Schultz}
\begin{document}
\title{Algorithms}
\author{William Schultz}
\maketitle

\newcommand{\concept}[1]{\textcolor{blue}{\textit{\textbf{#1}}}}

\section{Graph Search}

Can think about general graph search algorithm as consisting of an \textit{explored} set of nodes and a \textit{frontier} set of nodes. The goal is to eventually have the explored set equal to all nodes in the graph. The frontier is a set of nodes that we maintain along the way. Initially, we set the frontier to the starting node of the graph. It is unexplored but currently on our list of nodes that need to be explored i.e. it is on the frontier. We then pick a new node from the frontier set, mark it as explored, and do any other work we might need to do, and then take all of its neighbors and add them to the frontier set.

\subsection{Depth-first search}
Depth-first search searches deeper in a graph before searching broader. Can do a basic recursive or iterative implementation. Iterative implementation uses a stack to keep track of the frontier nodes, so that we explore deeper nodes first. We can also implement depth first search in a way that lets us recover paths to a node, by storing parent pointers as we go.

\subsection{Breadth-first search}
Breadth-first search searches all closer nodes before searching farther nodes i.e. it progresses in "levels" of depth. Not a standard way to implement it recursively, but can use a queue to keep track of the frontier nodes.

\section{Dynamic Programming}

There are 2 main components of a problem that make it amenable to a so-called ``dynamic programming'' (badly named) approach:
\begin{enumerate}
    \item \textbf{Optimal Substructure}: A global solution can be described in terms of solutions to smaller ``local'' problems. In other words, it is possible to find a solution to a larger problem by solving smaller problems and combine them in an efficient way. 
    \item \textbf{Overlapping Subproblems}: The global problem can be broken down into smaller ``local" sub-problems, and there is some overlap/redundancy between these subproblems, which is where you ideally get the efficiency speedup from.
\end{enumerate}
Note that either (1) and (2), in isolation, don't necessarily permit an efficient, dynamic programming based approach to a problem. For example, we can consider \textit{divide and conquer} type approaches as satisfying the \textit{optimal substructure} property, but don't necessarily satisfy the \textit{overlapping ubproblems} property. For example, merge sort solves smaller subproblems (subsequences of an original list) and then merges them into a larger solution. But, in general, these smaller sorting problems cannot be expected to actually overlap at all.

Examples of problems with efficient DP approaches:
\begin{enumerate}
    \item \textbf{Fibonacci}: Compute the $n$-th Fibonacci number.
    \item \textbf{Subset Sum}: Given a set (multi-set) $S$ of integers and a target sum $k$, determine if there is a subset of $X \subseteq S$ such that the sum of integers in $X$ equals $k$.
    \item \textbf{Knapsack}: 
    \item \textbf{Weighted Interval Scheduling}: Given a set of intervals $(s_i,e_i, W_i)$ represent as start and end times $s_i$ and $e_i$, respectively, and weight $W_i$, determine the maximum weight set of non-overlapping intervals.
    \item \textbf{Minimum Edit Distance}: Given two strings $S$ and $T$ over some alphabet of characters $\Sigma$, determine the minimum number of insertions or deletions needed to transform $S$ to $T$.
    \item \textbf{Matrix Chain Multiplication}: Given a sequence of matrices, determine the most efficient order in which to multiple them
\end{enumerate}



Can also look at some problems as having solution that can be built by a sequence of choices of which elements to add to the solution. This also allows for a more unified view in some cases between a greedy approach and a DP approach. For example, in the \textit{Subset Sum} problem, we can imagine a strategy where we build a solution by picking new elements from the original set to add to our output solution. We might take some kind of greedy approach where we, for example, pick the next smallest value and add it to our output. Clearly, the issue with the greedy approach in this problem is that it can get ``stuck'', with no next choices that allow the solution to be rectified, even if a solution does exist.


\section*{Algorithms Problem List}

\subsection*{Merge Strings Alternately}
\begin{itemize}
    \item \textbf{Problem}: Given two strings $s_1$ and $s_2$, merge them into one string $S$ such that the output string $S$ interleaves the characters of $s_1$ and $s_2$ alternately. If one string is longer than the other, then we append the remaining characters of that string to the end of the output string.
\end{itemize}


\subsection*{Greatest Common Divisor of Strings}
\begin{itemize}
    \item \textbf{Problem}: Given two strings $s$ and $t$, we say that $t$ ``divides'' $s$ if $s = t + t + \dots + t$. That is, $s$ consists of $t$ concateneated with  itself 1 or more times. Given two strings $s_1$ and $s_2$, we want to find the greatest common divisor $x$ between $s_1$ and $s_2$. That is, the largest string $x$ such that $x$ divides $s_1$ and $s_2$.
\end{itemize}

\subsection*{Kids with Greatest Number of Candies}
\begin{itemize}
    \item \textbf{Problem}: Given array of kids with some number of candies, and number of extra candides, compute whehter each kid would have max candies after receiving the number of extra candies you have.
\end{itemize}

\subsection*{Merge k Sorted Lists}

\begin{itemize}
    \item \textbf{Problem}: Given a set of $k$ linked lists, each which are individually sorted in ascending order, merge all $k$ lists into one sorted list. 
    \item \textbf{Solution Idea}: The basic approach is to essentially just perform the \textit{merge} step of merge-sort. That is, if we are given a set of already sorted lists, we can merge them all into one sorted lists by repeatedly popping the smallest element from the remaining, non-empty lists and appending it to the output list.
    \item \textbf{Key Concepts}: 
    \begin{itemize}
        \item \concept{Mergesort Merging}
        \item \concept{Linked List Manipulation}
    \end{itemize}
    The essence of the solution is very straightforward as long as you know and understand the ideas behind mergesort i.e. knowing the core idea that you can merge a set of already sorted lists by incrementally choosing the smallest element from each.
\end{itemize}

\subsection*{Remove duplicates from sorted linked list}
\begin{itemize}
\item \textbf{Problem}: Given a sorted linked list, remove any duplicates from the list.
\item \textbf{Solution Idea}: Iterate through the linked list, but at each node look ahead to see how many nodes in front of you contain an identical value to your own. Update your current ``next" pointer to point to the first node after this block of identical nodes in front of you. Since the list is sorted, you know that any duplicates of the current value must be directly in front of you.
\item \textbf{Key Concepts}: 
\begin{itemize}
    \item \concept{Linked List Traversal}
    \item \concept{Linked List Deletion}
    \item \concept{Duplicate Detection by Sorting}
\end{itemize}
The underlying insight in the solution is to recognize that sorting a list can be used an easy mechanism for detecting duplicates. That is, in a sorted list, all duplicates of a particular item will always appear in contiguous ``blocks". Once you recognize this fact, then implementing the solution mostly requires a standard application of linked list iteration and linked list item deletion. Namely, that to delete an item $n_2$ from a linked list that appears in a list as $n1 \rightarrow n_2 \rightarrow n_3$, you simply update  the ``next" pointer of $n_1$ to point to $n_3$ instead of $n_2$. Recall that a basic linked list node is a $LinkedListNode(val, next)$ structure, where $val$ is the value of that node, and $next$ is a pointer to the next item in the list.
\end{itemize}

\subsection*{Intersection of two linked lists}
\begin{itemize}
\item \textbf{Problem}: Given two singly linked lists, return the node at which the two lists intersect. If they have no intersection, then return \textit{null}.
\item \textbf{Solution Idea}: This is similar to a \textit{lowest common ancestor} problem. One approach is to walk backwards to the root from one of the lists and keep track of all nodes seen along the way. Then, walk backwards from the other list and check for the first node you hit that was already seen, and that node should be the intersection point. Note that this uses $O(n)$ space, if $n$ the upper bound on the size of the linked lists. 

It's also possible to do it without using any extra space by using a cleverer 2 pointer approach with a bit of counting. If we walk back to the root in both lists we can record the longer of the two. Then, from this we know the difference in length between the two lists, $diff$. So, we can walk backwards by $diff$ pointers in the longer list, and then walk forwards from there in both lists at the same time, until we hit a point where both pointers are pointing to the same node.
\item \textbf{Key Concepts}:
\begin{itemize}
    \item \concept{Linked List Traversal}
    \item \concept{Lowest Common Ancestor (?)}
\end{itemize}
\end{itemize}

\subsection*{Reverse linked list}
\begin{itemize}
\item \textbf{Problem}: Given a singly linked list, reverse the list.
\item \textbf{Solution Idea}: Iterate over the list and at each node, re-arrange the \textit{next} pointer so it now points to the previous node rather than the next node.
\begin{align*}
    None \rightarrow a \rightarrow b \rightarrow c
\end{align*}
If $curr=a$ and $curr.next = b$, then to do the reversal we want to end up with $a.next = None$ and then step forward, ending up with $curr=b$. So, at each step of the traversal, we keep track of hte previous item we looked at, so that we can reverse the pointer of the current node to point to it. We also need to save a reference to the next node before we update it.
\item \textbf{Key Concepts}:
\begin{itemize}
    \item \concept{Linked List Traversal}
    \item \concept{Pointer Swapping (?)}
\end{itemize}
Need to have a solid grasp of how to traverse a linked list, but also need to have good confidence in how to update points in a few steps (similar to how we swap variables), without overwriting the info we need to continue.
\end{itemize}

\subsection*{Add two binary strings}
% \begin{itemize}
% \item \textbf{Problem}: Given a singly linked list, reverse the list.
% \item \textbf{Solution Idea}: Iterate over the list and at each node, re-arrange the \textit{next} pointer so it now points to the previous node rather than the next node.
% \begin{align*}
%     None \rightarrow a \rightarrow b \rightarrow c
% \end{align*}
% If $curr=a$ and $curr.next = b$, then to do the reversal we want to end up with $a.next = None$ and then step forward, ending up with $curr=b$. So, at each step of the traversal, we keep track of hte previous item we looked at, so that we can reverse the pointer of the current node to point to it. We also need to save a reference to the next node before we update it.
% \item \textbf{Key Concepts}:
% \begin{itemize}
%     \item \concept{Linked List Traversal}
%     \item \concept{Pointer Swapping (?)}
% \end{itemize}
% Need to have a solid grasp of how to traverse a linked list, but also need to have good confidence in how to update points in a few steps (similar to how we swap variables), without overwriting the info we need to continue.
% \end{itemize}

\subsection*{Subsets of a list}

% \bibliographystyle{plain}
% \bibliography{../../references.bib}

\end{document}