<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="William Schultz" />
  <meta name="author" content="William Schultz" />
  <title>Distributed Systems</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <link rel="stylesheet" href="../../style.css" />
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Distributed Systems</h1>
<p class="author">William Schultz</p>
<p class="author">William Schultz</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#system-models"><span class="toc-section-number">1</span> System Models</a></li>
<li><a href="#fault-tolerance"><span class="toc-section-number">2</span> Fault Tolerance</a></li>
<li><a href="#consensus-and-mutual-exclusion"><span class="toc-section-number">3</span> Consensus and Mutual Exclusion</a>
<ul>
<li><a href="#single-machine-concurrent-consensus-with-locks"><span class="toc-section-number">3.1</span> Single Machine, Concurrent Consensus with Locks</a></li>
<li><a href="#single-machine-concurrent-consensus-without-locks"><span class="toc-section-number">3.2</span> Single Machine, Concurrent Consensus without Locks</a></li>
</ul></li>
<li><a href="#byzantine-fault-tolerance"><span class="toc-section-number">4</span> Byzantine Fault Tolerance</a>
<ul>
<li><a href="#model"><span class="toc-section-number">4.1</span> Model</a></li>
<li><a href="#intuitions-and-algorithm"><span class="toc-section-number">4.2</span> Intuitions and Algorithm</a></li>
<li><a href="#notes"><span class="toc-section-number">4.3</span> Notes</a></li>
</ul></li>
<li><a href="#bibliography">References</a></li>
</ul>
</nav>
<section id="system-models" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> System Models</h1>
<ul>
<li><p>In a <strong>synchronous</strong> message passing system, there exists some known finite bound <span class="math inline">\(\Delta\)</span> on message delays. That is, for any message sent, an adversary can delay its delivery by at most <span class="math inline">\(\Delta\)</span>. So, every process that sends messages at time <span class="math inline">\(t\)</span> gets them delivered by time <span class="math inline">\(t+\Delta\)</span>. i.e., the whole system runs in lockstep, marching forward in perfectly synchronous rounds. For example, <span class="citation" data-cites="2018abrahamsyncbyz">(<a href="#ref-2018abrahamsyncbyz" role="doc-biblioref">Abraham et al. 2019</a>)</span> provides a standard (modern) description of the synchronous model:</p>
<blockquote>
<p>If an honest party <span class="math inline">\(i\)</span> sends a message to another honest party <span class="math inline">\(j\)</span> at the beginning of a round, the message is guaranteed to reach by the end of that round. We describe the protocol assuming lock-step execution, i.e., parties enter and exit each round simultaneously. Later...we will present a clock synchronization protocol to bootstrap lock-step execution from bounded message delay.</p>
</blockquote></li>
<li><p>In a fully <strong>asynchronous</strong> model, there is no upper bound on the delay for a message to be delivered, but we do assume that the delay is some finite value (e.g. chosen by an adversary). So, even though the message delay may be some unknown/unbounded quantity, we do assume that every message eventually gets delivered, even if the delay is unknown a priori.</p>
<p>The nature of asynchronous networks also implies that there is no way to have a perfect failure detector in a fully asynchronous system, since you can’t distinguish between a failed/stopped process and one whose messages are just taking a long time to get delivered.</p></li>
<li><p>The <strong>partial synchrony</strong> model aims to find a middle ground between the two above models. The assumption is that there exists some known finite time bound <span class="math inline">\(\Delta\)</span> and a special event called GST (global stabilization time) such that:</p>
<ul>
<li><p>The adversary must cause the GST event to eventually happen after some unknown finite time.</p></li>
<li><p>Any message sent at time <span class="math inline">\(x\)</span> must be delivered by <span class="math inline">\(\Delta + max(x, GST)\)</span>. That is, after the GST, messages are delivered within the known finite time bound <span class="math inline">\(\Delta\)</span> (i.e. the system has “reverted" to synchrony).</p></li>
</ul></li>
</ul>
<p><em>What are the fundamental differences between the synchronous and asynchronous models, and what exactly makes the latter harder?</em></p>
</section>
<section id="fault-tolerance" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Fault Tolerance</h1>
<p>There are some fundamental requirements to establish bounds for fault tolerance in an omission fault model. If an arbitrary set of <span class="math inline">\(f\)</span> nodes can fail by stopping at any time, then this means that if we want a protocol that makes progress, we would need to ensure that any “work” we do (e.g. executing operations, writing down data, etc.) is made sufficiently redundant so that it can be accessed even in the case of maximum node failure. So, this implies we need to write all data to at least <span class="math inline">\(f+1\)</span> nodes, so that there is always at least one non-faulty node with the data we need to access.</p>
<p>This seems to imply that having <span class="math inline">\(f+1\)</span> nodes might be sufficient for a protocol to be fault tolerant. But, this doesn’t satisfy a progress requirement. That is, if we now need to write everything down to <span class="math inline">\(f+1\)</span> nodes, then failure of <span class="math inline">\(f\)</span> out of <span class="math inline">\(f+1\)</span> nodes would clearly stall our protocol, since it can’t do any work safely. So, our additional requirement is that both:</p>
<ol type="1">
<li><p>Write any work down to <span class="math inline">\(f+1\)</span> nodes.</p></li>
<li><p>Always have <span class="math inline">\(f+1\)</span> non-faulty nodes available that we can write work down on.</p></li>
</ol>
<p>Thus, this naturally gives us a total node requirement of <span class="math display">\[\begin{aligned}
    n = (f+1) + f = 2f + 1\end{aligned}\]</span> That is, even in the case of <span class="math inline">\(f\)</span> maximum node failures, we will always have <span class="math inline">\(f+1\)</span> nodes available to us to write down our work, allowing us to make progress.</p>
</section>
<section id="consensus-and-mutual-exclusion" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Consensus and Mutual Exclusion</h1>
<p>The problem of <em>consensus</em> in a distributed system is to get a set of separate nodes to agree on a single value. That is, if one node marks a value as chosen, no other node can ever mark a different value as chosen. To understand the constraints of how we might solve this problem, we can start by thinking about this problem in a simpler setting e.g. a single (non-distributed) node. For an individual node/thread, solving consensus is trivial, since that node/thread can just write into a single register and then never change its decision. But, even when we introduce multiple concurrent clients (e.g. threads), the problem is nontrivial.</p>
<section id="single-machine-concurrent-consensus-with-locks" class="level2" data-number="3.1">
<h2 data-number="3.1"><span class="header-section-number">3.1</span> Single Machine, Concurrent Consensus with Locks</h2>
<p>We assume we have a single register which represents our consensus “object", and we have multiple threads that can access the register. That is, they can read or write a value to the register atomically. If we have a locking primitive available, then we can solve the single register consensus problem easily. Each thread just acquires a global lock before it tries to do anything, reads the register to check if it has already been written to, and if it has, then do nothing, and if it hasn’t, then go ahead and write whatever value you want. It is obvious to see that this upholds the basic correctness properties of consensus.</p>
</section>
<section id="single-machine-concurrent-consensus-without-locks" class="level2" data-number="3.2">
<h2 data-number="3.2"><span class="header-section-number">3.2</span> Single Machine, Concurrent Consensus without Locks</h2>
<p>Now, what if we want to consider solving the above problem without locks? And why would we need do do this? Well, first, we can imagine that if we eventually want a solution that generalizes to the distributed setting, we won’t be able to rely on locks as a fundamental mutual exclusion primitive, since a global lock primitive won’t exist in a distributed setting. Additionally, locks necessarily present a potential impediment to system progress, if we assume that threads can fail or run slowly. That is, if locks can be taken unilaterally by some thread and only released by that thread, this presents potential liveness issues if that thread fails to make progress for some time and other nodes cannot proceed. So, coming up with a lock-less solution to the consensus problem seems a reasonable/desirable goal.</p>
<p>If we think about the fundamental requirements of consensus in this “single register” model, it boils down to a simple high level requirement that threads must satisfy:</p>
<blockquote>
<p>R1. If a thread writes a value <span class="math inline">\(v\)</span> to the register, then it should not differ from the most recently written value.</p>
</blockquote>
<p>This is the very basic, fundamental requirement, simply stating that whenever somebody tries to write to the register they better not overwrite an already existing, different value in the register. In order to start working out a lock-less solution to the problem, let’s consider how the lock-based solution satisfies this above requirement.</p>
<p>In the lock-based solution we can think about every thread as executing a simple request/transaction, that consists of the following steps:</p>
<pre><code>    acquire(lock)
    if read(X) is not set:
        write(X, v)
    release(lock)</code></pre>
<p>where <code>lock</code> is the global lock shared by all threads, and <code>X</code> represents our register object, and <code>v</code> is some arbitrary value the thread chooses to write. How does such a procedure satisfy the above requirement R1? Well, first, the locking mechanism ensures that all operations are explicitly/globally ordered with respect to each other i.e. their order is dynamically assigned based on the order of lock acquisition. Based on this, it is clear then, that</p>
<ol>
<li><p>Reads of a transaction <span class="math inline">\(T\)</span> see the effect of the value written by the most recent transaction ordered earlier than <span class="math inline">\(T\)</span>.</p></li>
<li><p>After a transaction <span class="math inline">\(T\)</span> that is currently holding the lock completes its read, no future writes will ever be made by transactions ordered earlier <span class="math inline">\(T\)</span>.</p></li>
</ol>
<p>Note that (C2) is an important but subtle condition that is required for safety. Simply reading the most recently written value is not sufficient to ensure correctness, since this doesn’t say anything about writes that may occur <em>after</em> the read but <em>before</em> the subsequent write of the transaction. In other words, you need to protect against concurrent transaction writes that would invalidate the results of your read.</p>
<p>Ok, so let’s try to take ideas from the lock-based solution and turn them into a lock-less solution. One main idea is that there is an implicit order/sequence assigned to all transactions in the lock-based approach. We might say this ordering is “implicit" or “on demand" because transactions don’t really get ordered until they try to go ahead and acquire a lock. At that point, we can imagine them being implicitly assigned some sequence number in a global sequence of transactions based on the order of their lock acquisition. So, if we don’t want to rely on locks, but we know that this global ordering notion works for a lock-based solution, can we try to develop an ordering mechanism that doesn’t rely on locks?</p>
<p>Well, the naive approach is to basically just pre-assign global, totally ordered sequence numbers to all transactions. We could imagine a variety of schemes for doing this, but if we’re still in a single machine context, we could imagine simply having a global atomic counter that hands out sequence numbers to transactions before they start. Alternatively, we could imagine handing out disjoint, evenly distributed sets of sequence numbers to each thread at system initialization, that they can draw from whenever they want to start a new transaction. For simplicity, we can kind of ignore the details of how such an ordering assignment scheme works, but we can assume that there is some way to uniquely assign uniquely global, totally ordered sequence numbers to different transactions (note that Paxos similarly does this in a similar manner, by pre-assigning disjoint sets of proposal ids to to each proposer).</p>
<p>Now, if we assume that all transactions are tagged with a unique, totally ordered sequence number, we can try to use this to build a complete, lock-less solution to the single register consensus problem. As shown above, each thread can still execute a similar procedure as before, but it will do so without acquisition/release of locks and with a bit of extra checking related to their sequence numbers. As we said above, all that threads need to ensure are conditions (C1) and (C2). Let’s consider them independently, starting with C2 first.</p>
<ul>
<li><p>(C2) This condition is fairly straightforward to handle. Whenever transaction <span class="math inline">\(T\)</span> with sequence number <span class="math inline">\(n\)</span> does a read, it can tag the register with sequence number <span class="math inline">\(n\)</span>. Then, subsequent writes from transactions in sequence numbers <span class="math inline">\(k\)</span> can check their sequence number against <span class="math inline">\(n\)</span>. If <span class="math inline">\(k &lt; n\)</span> then we can prevent the write from occurring, and if <span class="math inline">\(k  \geq n\)</span>, then we can allow the write to succeed. This clearly ensures that once a read occurs by transaction in sequence number <span class="math inline">\(n\)</span>, no future writes can be made to the register by transactions ordered <span class="math inline">\(&lt; n\)</span>.</p></li>
<li><p>(C1) This condition is a bit more tricky, since it is complicated by the fact that we no longer assume a global serialization order between transaction operations as we did in the lock-based solution. For example, if we make a fundamental assumption that transaction operations may be always be interleaved in arbitrary orders (based on the fact that we have no global locking/mutex primitive), how can we possibly satisfy C1 in a case like the following,</p>
<pre><code>        read:2(X)
        write:1(X, v)</code></pre>
<p>where <code>op:seqno</code> indicates that <code>op</code> is an operation from transaction with sequence number <code>seqno</code>? That is, how can we ever enforce that a read from transaction at sequence number <span class="math inline">\(n\)</span> will necessarily see the writes from transactions at sequence numbers <span class="math inline">\(&lt; n\)</span>, if it can’t forcibly protect against such transactions doing future writes after the transaction in <span class="math inline">\(n\)</span> does its read? Well, we can’t be sure, if we make the fundamental concurrency/interelaving assumption above. So, this is where C2 comes into play to help us. Instead of trying to ensure C1 exactly, we just explicitly prevent any future writes that would violate it. If some writes have already occurred in sequence numbers <span class="math inline">\(&lt; n\)</span>, then we will obviously read their effects when we read at <span class="math inline">\(&lt; n\)</span>, but then after we read at <span class="math inline">\(n\)</span>, we just force the system to never execute a write at a transaction number <span class="math inline">\(&lt; n\)</span> in the future. Note also that we aren’t really impairing ourselves unnecessarily here. That is,once a transaction in sequence number <span class="math inline">\(n\)</span> has started, we make the implicit assumption that it “overrules” any transactions in earlier sequence numbers, so there’s not really any point in letting an earlier transaction go ahread and write when a higher transaction number has already started anyway. So, we can view it as acceptable to just rule out these “stale” writes anyway.</p></li>
</ul>
</section>
</section>
<section id="byzantine-fault-tolerance" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Byzantine Fault Tolerance</h1>
<p>The earliest explicit reference to <em>Byzantine</em> faults appeared in <span class="citation" data-cites="1982lamportshostak">(<a href="#ref-1982lamportshostak" role="doc-biblioref">Lamport, Shostak, and Pease 1982</a>)</span>, though earlier work had touched on the same problem without referring to it by that moniker <span class="citation" data-cites="1980peasereaching 1978sift">(<a href="#ref-1980peasereaching" role="doc-biblioref">Pease, Shostak, and Lamport 1980</a>; <a href="#ref-1978sift" role="doc-biblioref">Wensley et al. 1978</a>)</span>. They show in <span class="citation" data-cites="1982lamportshostak">(<a href="#ref-1982lamportshostak" role="doc-biblioref">Lamport, Shostak, and Pease 1982</a>)</span> that when using “oral” messages (i.e. non-signed) messages, a Byzantine agreement solution requires <span class="math inline">\(3f+1\)</span> processes, even in a synchronous communication model. They give an algorithm that solves the problem assuming <span class="math inline">\(n &gt; 3f+1\)</span>, and also show that if we allow for “written” (e.g. digitally signed) messages, then in the synchronous model Byzantine agreement can be achieved with only <span class="math inline">\(f+1\)</span> processes.</p>
<section id="model" class="level2" data-number="4.1">
<h2 data-number="4.1"><span class="header-section-number">4.1</span> Model</h2>
<p>The work on Practical Byzantine Fault Tolerance <span class="citation" data-cites="1999castropbft">(<a href="#ref-1999castropbft" role="doc-biblioref">Castro and Liskov 1999</a>)</span> considers an asynchronous distributed system where nodes are connected by a network which can fail to deliver messages, delay them, or deliver them out of order. Furthermore, it considers a Byzantine failure model i.e., faulty nodes may behave arbitrarily, subject only to the above restrictions. They do assume, however, cryptographic techniques that prevent spoofing and can detect corrupted messages. In other words, Byzantine processes can send any message, but we assume the identity of the sender of a message can be determined by the receiver <span class="citation" data-cites="2011lamport">(<a href="#ref-2011lamport" role="doc-biblioref">Lamport 2011</a>)</span>. This can be achieved this with public-key signatures <span class="citation" data-cites="1978rivestcrypto">(<a href="#ref-1978rivestcrypto" role="doc-biblioref">Rivest, Shamir, and Adleman 1978</a>)</span>, message authentication codes (MACs), etc.</p>
</section>
<section id="intuitions-and-algorithm" class="level2" data-number="4.2">
<h2 data-number="4.2"><span class="header-section-number">4.2</span> Intuitions and Algorithm</h2>
<p>If we assume a starting point of a classic 2-phase Paxos consensus approach, the following are some of the essential issues that arise and must be dealt with when we add in Byzantine faults:</p>
<ol>
<li><p><strong>Leader equivocation</strong>: if a leader is faulty (Byzantine), then it can trivially send two conflicting messages in the same view (i.e. with the same proposal number). This means that, for example, it could send out and accept message with its own proposal number but with a different value to each replica. Then, we would end up with a quorum of replicas having accepted that proposal, but they all have different values, so which one is the true value to agree upon?</p></li>
<li><p><strong>Wrong value adoption</strong>: A leader (faulty or not) that accepts a wrong value (i.e. not highest among previously) chosen can lead to safety violation as considered in the standard 2-phase Paxos model.</p></li>
</ol>
<p>A key idea of the algorithm is about how we deal with the issue of potentially Byzantine leaders. That is, we need to protect against leaders sending conflicting messages to different followers such that we would violate the constraints needed to ensure safety in, for example, classic asynchronous consensus Paxos in the standard omission (non Byzantine) fault model. If a leader is faulty and just went ahead and followed the standard 2-phase protocol used in Paxos (<em>prepare</em> + <em>accept</em>), then in the <em>prepare</em> phase it could tell different replicas arbitrarily different things i.e. tell them to accept one value and then change this value</p>
<p><strong>Note:</strong> focus on reasoning about the protocol from ground up by looking at two special cases:</p>
<ul>
<li><p>Faulty acceptors (can’t trust 1b or 2b messages of classic Paxos since acceptors can lie)</p></li>
<li><p>Faulty proposers/leaders (can’t trust 1a or 2a messages of classic Paxos since proposers can lie)</p></li>
</ul>
<p>Need to have ways to protect against both scenarios. Generally, for the faulyty acceptor case, we need to increase our quorum sizes in a way that ensures a propsoer can gather enough responses to be sure a sufficient number of honest responses were received. For faulty proposers, acceptors will need to implement some additional safety check to guard against proposers sending dishonest messages about values to be proposers/accepted.</p>
<p>The essence of the algorithm is as follows:</p>
<ol>
<li><p>Primary sends a <span class="math inline">\(pre\_prepare(value, p)\)</span> message for view/proposal number <span class="math inline">\(p\)</span>.</p></li>
<li><p>Replica responds to the first <span class="math inline">\(pre\_prepare\)</span> message it receives from a primary.</p></li>
<li><p>Primary gathers <span class="math inline">\(pre\_prepare\)</span> responses from <span class="math inline">\(n-f\)</span> replicas, and then sends <span class="math inline">\(prepare(v, proof)\)</span> (note this message may be linear in size since it contains signed codes fro m up to <span class="math inline">\(n\)</span> nodes.)</p></li>
<li><p>If a replica sees <span class="math inline">\(prepare(value, p, proof)\)</span> and <span class="math inline">\(proof\)</span> contains <span class="math inline">\(n-f\)</span> valid signatures for <span class="math inline">\(pre\_prepare(value, p)\)</span>, then it goes ahead and accepts.</p></li>
<li><p>Primary then gathers <span class="math inline">\(n-f\)</span> <span class="math inline">\(prepare\)</span> responses from replicas.</p></li>
</ol>
<p>Note that since we assume a public key infrastructure (PKI) set up between nodes of the system, any node can securely verify that a message was signed by some another node.</p>
</section>
<section id="notes" class="level2" data-number="4.3">
<h2 data-number="4.3"><span class="header-section-number">4.3</span> Notes</h2>
<ul>
<li><p>Given <span class="math inline">\(n=3f+1\)</span> nodes, for any 2 quorums with <span class="math inline">\(n-f = 2f+1\)</span> nodes, we are guaranteed they intersect in at least <span class="math inline">\(f+1\)</span> nodes (just draw a picture). Note that if you talk to at least <span class="math inline">\(f+1\)</span> nodes then you are sure you are in contact with at least one non-faulty (non-Byzantine) node.</p></li>
</ul>
</section>
</section>
<section id="bibliography" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-2018abrahamsyncbyz" class="csl-entry" role="doc-biblioentry">
Abraham, Ittai, Srinivas Devadas, Danny Dolev, Kartik Nayak, and Ling Ren. 2019. <span>“Synchronous Byzantine Agreement with Expected o(1) Rounds, Expected Communication, and Optimal Resilience.”</span> In <em>Financial Cryptography and Data Security: 23rd International Conference, FC 2019, Frigate Bay, St. Kitts and Nevis, February 18–22, 2019, Revised Selected Papers</em>, 320–34. Berlin, Heidelberg: Springer-Verlag. <a href="https://doi.org/10.1007/978-3-030-32101-7_20">https://doi.org/10.1007/978-3-030-32101-7_20</a>.
</div>
<div id="ref-1999castropbft" class="csl-entry" role="doc-biblioentry">
Castro, Miguel, and Barbara Liskov. 1999. <span>“Practical Byzantine Fault Tolerance.”</span> In <em>Proceedings of the Third Symposium on Operating Systems Design and Implementation</em>, 173–86. OSDI ’99. USA: USENIX Association.
</div>
<div id="ref-2011lamport" class="csl-entry" role="doc-biblioentry">
Lamport, Leslie. 2011. <span>“Byzantizing Paxos by Refinement.”</span> In <em>Proceedings of the 25th International Conference on Distributed Computing</em>, 211–24. DISC’11. Berlin, Heidelberg: Springer-Verlag.
</div>
<div id="ref-1982lamportshostak" class="csl-entry" role="doc-biblioentry">
Lamport, Leslie, Robert Shostak, and Marshall Pease. 1982. <span>“<span>The Byzantine Generals Problem</span>.”</span> <em>ACM Trans. Program. Lang. Syst.</em> 4 (3): 382–401. <a href="https://doi.org/10.1145/357172.357176">https://doi.org/10.1145/357172.357176</a>.
</div>
<div id="ref-1980peasereaching" class="csl-entry" role="doc-biblioentry">
Pease, M., R. Shostak, and L. Lamport. 1980. <span>“Reaching Agreement in the Presence of Faults.”</span> <em>J. ACM</em> 27 (2): 228–34. <a href="https://doi.org/10.1145/322186.322188">https://doi.org/10.1145/322186.322188</a>.
</div>
<div id="ref-1978rivestcrypto" class="csl-entry" role="doc-biblioentry">
Rivest, R. L., A. Shamir, and L. Adleman. 1978. <span>“A Method for Obtaining Digital Signatures and Public-Key Cryptosystems.”</span> <em>Commun. ACM</em> 21 (2): 120–26. <a href="https://doi.org/10.1145/359340.359342">https://doi.org/10.1145/359340.359342</a>.
</div>
<div id="ref-1978sift" class="csl-entry" role="doc-biblioentry">
Wensley, J. H., L. Lamport, J. Goldberg, M. W. Green, K. N. Levitt, P. M. Melliar-Smith, R. E. Shostak, and C. B. Weinstock. 1978. <span>“SIFT: Design and Analysis of a Fault-Tolerant Computer for Aircraft Control.”</span> <em>Proceedings of the IEEE</em> 66 (10): 1240–55. <a href="https://doi.org/10.1109/PROC.1978.11114">https://doi.org/10.1109/PROC.1978.11114</a>.
</div>
</div>
</section>
</body>
</html>
