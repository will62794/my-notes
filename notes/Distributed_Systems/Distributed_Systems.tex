\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{verbatim}
\usepackage{enumerate}
\usepackage{fancyvrb}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{tcolorbox}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes,snakes}
\usepackage[english]{babel}

\geometry{legalpaper, margin=1.5in}

\author{William Schultz}
\begin{document}
\title{Distributed Systems}
\author{William Schultz}
\maketitle

\section{System Models}

\begin{itemize}
    \item In a \textbf{synchronous} message passing system, there exists some known finite bound $\Delta$ on message delays. That is, for any message sent, an adversary can delay its delivery by at most $\Delta$. So, every process that sends messages at time $t$ gets them delivered by time $t+\Delta$. i.e., the whole system runs in lockstep, marching forward in perfectly synchronous rounds. For example, \cite{2018abrahamsyncbyz} provides a standard (modern) description of the synchronous model: 
    
    \begin{quote}
    If an honest party $i$ sends a message to another honest party $j$ at the beginning of a round, the message is guaranteed to reach by the end of that round. We describe the protocol assuming lock-step execution, i.e., parties enter and exit each round simultaneously. Later...we will present a clock synchronization protocol to bootstrap lock-step execution from bounded message delay.
    \end{quote}
    
    \item  In a fully \textbf{asynchronous} model, there is no upper bound on the delay for a message to be delivered, but we do assume that the delay is some finite value (e.g. chosen by an adversary).  So, even though the message delay may be some unknown/unbounded quantity, we do assume that every message eventually gets delivered, even if the delay is unknown a priori.
    
    The nature of asynchronous networks also implies that there is no way to have a perfect failure detector in a fully asynchronous system, since you can't distinguish between a failed/stopped process and one whose messages are just taking a long time to get delivered.

    \item The \textbf{partial synchrony} model aims to find a middle ground between the two above models. The assumption is that there exists some known finite time bound $\Delta$ and a special event called GST (global stabilization time) such that:
    \begin{itemize}
        \item The adversary must cause the GST event to eventually happen after some unknown finite time.
        \item Any message sent at time $x$ must be delivered by $\Delta + max(x, GST)$. That is, after the GST, messages are delivered within the known finite time bound $\Delta$ (i.e. the system has ``reverted" to synchrony).
    \end{itemize}
\end{itemize}

\textit{What are the fundamental differences between the synchronous and asynchronous models, and what exactly makes the latter harder?}

\section{Fault Tolerance}

There are some fundamental requirements to establish bounds for fault tolerance in an omission fault model. If an arbitrary set of $f$ nodes can fail by stopping at any time, then this means that if we want a protocol that makes progress, we would need to ensure that any ``work'' we do (e.g. executing operations, writing down data, etc.) is made sufficiently redundant so that it can be accessed even in the case of maximum node failure. So, this implies we need to write all data to at least $f+1$ nodes, so that there is always at least one non-faulty node with the data we need to access. 

This seems to imply that having $f+1$ nodes might be sufficient for a protocol to be fault tolerant. But, this doesn't satisfy a progress requirement. That is, if we now need to write everything down to $f+1$ nodes, then failure of $f$ out of $f+1$ nodes would clearly stall our protocol, since it can't do any work safely. So, our additional requirement is that both: 
\begin{enumerate}[1)]
    \item Write any work down to $f+1$ nodes.
    \item Always have $f+1$ non-faulty nodes available that we can write work down on.
\end{enumerate}
Thus, this naturally gives us a total node requirement of 
\begin{align*}
    n = (f+1) + f = 2f + 1
\end{align*}
That is, even in the case of $f$ maximum node failures, we will always have $f+1$ nodes available to us to write down our work, allowing us to make progress.


\section{Byzantine Fault Tolerance}

The earliest explicit reference to \textit{Byzantine} faults appeared in \cite{1982lamportshostak}, though earlier work had touched on the same problem without referring to it by that moniker \cite{1980peasereaching,1978sift}. They show in \cite{1982lamportshostak} that when using ``oral'' messages (i.e. non-signed) messages, a Byzantine agreement solution requires $3f+1$ processes, even in a synchronous communication model. They give an algorithm that solves the problem assuming $n > 3f+1$, and also show that if we allow for ``written'' (e.g. digitally signed) messages, then in the synchronous model Byzantine agreement can be achieved with only $f+1$ processes.

\subsection{Model}

The work on Practical Byzantine Fault Tolerance \cite{1999castropbft} considers an asynchronous distributed system where nodes are connected by a network which can fail to deliver messages, delay them, or deliver them out of order. Furthermore, it considers a Byzantine failure model i.e., faulty nodes may behave arbitrarily, subject only to the above restrictions. They do assume, however, cryptographic techniques that prevent spoofing and can detect corrupted messages. In other words, Byzantine processes can send any message, but we assume the identity of the sender of a message can be determined by the receiver \cite{2011lamport}. This can be achieved this with public-key signatures \cite{1978rivestcrypto}, message authentication codes (MACs), etc.

\subsection{Intuitions and Algorithm}

If we assume a starting point of a classic 2-phase Paxos consensus approach, the following are some of the essential issues that arise and must be dealt with when we add in Byzantine faults:
\begin{enumerate}
    \item \textbf{Leader equivocation}: if a leader is faulty (Byzantine), then it can trivially send two conflicting messages in the same view (i.e. with the same proposal number). This means that, for example, it could send out and accept message with its own proposal number but with a different value to each replica. Then, we would end up with a quorum of replicas having accepted that proposal, but they all have different values, so which one is the true value to agree upon?
    \item \textbf{Wrong value adoption}: A leader (faulty or not) that accepts a wrong value  (i.e. not highest among previously) chosen can lead to safety violation as considered in the standard 2-phase Paxos model.
\end{enumerate}
A key idea of the algorithm is about how we deal with the issue of potentially Byzantine leaders. That is, we need to protect against leaders sending conflicting messages to different followers such that we would violate the constraints needed to ensure safety in, for example, classic asynchronous consensus Paxos in the standard omission (non Byzantine) fault model. If a leader is faulty and just went ahead and followed the standard 2-phase protocol used in Paxos (\textit{prepare} + \textit{accept}), then in the \textit{prepare} phase it could tell different replicas arbitrarily different things i.e. tell them to accept one value and then change this value 

% Why exactly is it bad if a leader is Byzantine i.e. even in classic Paxos?

The essence of the algorithm is as follows:
\begin{enumerate}
    \item Primary sends a $pre\_prepare(value, p)$ message for view/proposal number $p$.
    \item Replica responds to the first $pre\_prepare$ message it receives from a primary.
    \item Primary gathers $pre\_prepare$ responses from $n-f$ replicas, and then sends $prepare(v, proof)$ (note this message may be linear in size since it contains signed codes fro   m up to $n$ nodes.)
    \item If a replica sees $prepare(value, p, proof)$ and $proof$ contains $n-f$ valid signatures for $pre\_prepare(value, p)$, then it goes ahead and accepts.
    \item Primary then gathers $n-f$ $prepare$ responses from replicas.
\end{enumerate}
Note that since we assume a public key infrastructure (PKI) set up between nodes of the system, any node can securely verify that a message was signed by some another node.

\subsection{Notes}
\begin{itemize}
    \item Given $n=3f+1$ nodes, for any 2 quorums with $n-f = 2f+1$ nodes, we are guaranteed they intersect in at least $f+1$ nodes (just draw a picture). Note that if you talk to at least $f+1$ nodes then you are sure you are in contact with at least one non-faulty (non-Byzantine) node.
\end{itemize}


\bibliographystyle{alpha}
\bibliography{../../references.bib}

\end{document}