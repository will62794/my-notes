@techreport{lamport1974on,
author = {Lamport, Leslie},
title = {On Self-stabilizing Systems},
year = {1974},
month = {December},
abstract = {This note was written upon reading Dijkstra's classic paper "Self-stabilizing Systems in Spite of Distributed Control" that appeared in the November 1974 issue of CACM (see [58]). It generalizes one of the algorithms in Dijkstra's paper from a line of processes to an arbitrary tree of processes. It also discusses the self-stabilizing properties of the bakery algorithm. I never tried to publish this note--probably because I regarded it as too small a piece of work to be worth a paper by itself.
The note contains the intriguing sentence: "There is a complicated modified version of the bakery algorithm in which the values of all variables are bounded." I never wrote down that version, and I'm not sure what I had in mind. But I think I was thinking of roughly the following modification. As a process waits to enter its critical section, it keeps reducing its number, not entering the critical section until its number equals one. A process p can reduce its number by at most one, and only when the next lower-numbered process's number is at least two less than p's number, and the next higher-numbered process is within one of p's number. I think I intended to use the techniques of [25] to allow reading and writing of numbers to remain non-atomic while maintaining the order of waiting processes. (If eventually all processes stop changing their numbers, then all processes will eventually read the correct numbers, allowing some process to progress.) At one time, I convinced myself that this algorithm is correct. But I never wrote a rigorous proof, so I don't know if it really works. Filling in the details and proving correctness should be a nice exercise.},
url = {https://www.microsoft.com/en-us/research/publication/self-stabilizing-systems/},
number = {CA 7412-0511},
}
@inproceedings{hance2021finding,
  title={Finding Invariants of Distributed Systems: It's a Small (Enough) World After All.},
  author={Hance, Travis and Heule, Marijn and Martins, Ruben and Parno, Bryan},
  booktitle={NSDI},
  pages={115--131},
  year={2021}
}
@inproceedings{goel2021symmetry,
  title={On Symmetry and Quantification: A New Approach to Verify Distributed Protocols},
  author={Goel, Aman and Sakallah, Karem},
  booktitle={NASA Formal Methods Symposium},
  pages={131--150},
  year={2021},
  organization={Springer}
}
@inproceedings{yao2021distai,
  title={DistAI: Data-Driven Automated Invariant Learning for Distributed Protocols},
  author={Yao, Jianan and Tao, Runzhou and Gu, Ronghui and Nieh, Jason and Jana, Suman and Ryan, Gabriel},
  booktitle={15th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 21)},
  pages={405--421},
  year={2021}
}
@article{goel2021towards,
  title={Towards an Automatic Proof of Lamport's Paxos},
  author={Goel, Aman and Sakallah, Karem A},
  journal={arXiv preprint arXiv:2108.08796},
  year={2021}
}
@article{mirzaie2020parameterized,
  title={Parameterized synthesis of self-stabilizing protocols in symmetric networks},
  author={Mirzaie, Nahal and Faghih, Fathiyeh and Jacobs, Swen and Bonakdarpour, Borzoo},
  journal={Acta Informatica},
  volume={57},
  number={1},
  pages={271--304},
  year={2020},
  publisher={Springer}
}
@inproceedings{lamport2005real,
  title={Real-time model checking is really simple},
  author={Lamport, Leslie},
  booktitle={Advanced Research Working Conference on Correct Hardware Design and Verification Methods},
  pages={162--175},
  year={2005},
  organization={Springer}
}
@misc{paxosuniqueproposalSOquestion,
  title={why does paxos proposalId need to be unique},
  publisher={StackOverflow},
  howpublished={https://stackoverflow.com/questions/45610160/why-does-paxos-proposalid-need-to-be-unique}
}
@inproceedings{padon2016ivy,
  title={Ivy: safety verification by interactive generalization},
  author={Padon, Oded and McMillan, Kenneth L and Panda, Aurojit and Sagiv, Mooly and Shoham, Sharon},
  booktitle={Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages={614--630},
  year={2016}
}
@article{albarghouthi2016maximal,
  title={Maximal specification synthesis},
  author={Albarghouthi, Aws and Dillig, Isil and Gurfinkel, Arie},
  journal={ACM SIGPLAN Notices},
  volume={51},
  number={1},
  pages={789--801},
  year={2016},
  publisher={ACM New York, NY, USA}
}
@inproceedings{zhang2020behavioral,
  title={A behavioral notion of robustness for software systems},
  author={Zhang, Changjian and Garlan, David and Kang, Eunsuk},
  booktitle={Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages={1--12},
  year={2020}
}
@InProceedings{howard_flex_paxos,
  author =	{Heidi Howard and Dahlia Malkhi and Alexander Spiegelman},
  title =	{{Flexible Paxos: Quorum Intersection Revisited}},
  booktitle =	{20th International Conference on Principles of Distributed Systems (OPODIS 2016)},
  pages =	{25:1--25:14},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-031-6},
  ISSN =	{1868-8969},
  year =	{2017},
  volume =	{70},
  editor =	{Panagiota Fatourou and Ernesto Jim{\'e}nez and Fernando Pedone},
  publisher =	{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{http://drops.dagstuhl.de/opus/volltexte/2017/7094},
  URN =		{urn:nbn:de:0030-drops-70947},
  doi =		{10.4230/LIPIcs.OPODIS.2016.25},
  annote =	{Keywords: Paxos, Distributed Consensus, Quorums}
}
@inproceedings{lopes2014weakest,
  title={Weakest precondition synthesis for compiler optimizations},
  author={Lopes, Nuno P and Monteiro, Jos{\'e}},
  booktitle={International Conference on Verification, Model Checking, and Abstract Interpretation},
  pages={203--221},
  year={2014},
  organization={Springer}
}
@inproceedings{black2000mutation,
  title={Mutation operators for specifications},
  author={Black, Paul E and Okun, Vadim and Yesha, Yaacov},
  booktitle={Proceedings ASE 2000. Fifteenth IEEE International Conference on Automated Software Engineering},
  pages={81--88},
  year={2000},
  organization={IEEE}
}
@article{bonakdarpour2012automated,
  title={Automated model repair for distributed programs},
  author={Bonakdarpour, Borzoo and Kulkarni, Sandeep S},
  journal={ACM SIGACT News},
  volume={43},
  number={2},
  pages={85--107},
  year={2012},
  publisher={ACM New York, NY, USA}
}
@inproceedings{chaouch2009reduction,
  title={A reduction theorem for the verification of round-based distributed algorithms},
  author={Chaouch-Saad, Mouna and Charron-Bost, Bernadette and Merz, Stephan},
  booktitle={International Workshop on Reachability Problems},
  pages={93--106},
  year={2009},
  organization={Springer}
}
@inproceedings{2019fasterkSAT,
author = {Hansen, Thomas Dueholm and Kaplan, Haim and Zamir, Or and Zwick, Uri},
title = {{Faster k-SAT Algorithms Using Biased-PPSZ}},
year = {2019},
isbn = {9781450367059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313276.3316359},
doi = {10.1145/3313276.3316359},
abstract = {The PPSZ algorithm, due to Paturi, Pudlak, Saks and Zane, is currently the fastest known algorithm for the k-SAT problem, for every k&gt;3. For 3-SAT, a tiny improvement over PPSZ was obtained by Hertli. We introduce a biased version of the PPSZ algorithm using which we obtain an improvement over PPSZ for every k≥ 3. For k=3 we also improve on Herli’s result and get a much more noticeable improvement over PPSZ, though still relatively small. In particular, for Unique 3-SAT, we improve the current bound from 1.308n to 1.307n.},
booktitle = {Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing},
pages = {578–589},
numpages = {12},
keywords = {randomized algorithm, satisfiability},
location = {Phoenix, AZ, USA},
series = {STOC 2019}
}
@misc{SE3satlowerbounds,
title={{What are the best current lower bounds on 3SAT?}},
url={https://cstheory.stackexchange.com/questions/93/what-are-the-best-current-lower-bounds-on-3sat},
howpublished = "\url{https://cstheory.stackexchange.com/questions/93/what-are-the-best-current-lower-bounds-on-3sat}",
}
@book{sipser2015,
author = {Sipser, Michael},
title = {Introduction to the Theory of Computation},
year = {1996},
isbn = {053494728X},
publisher = {International Thomson Publishing},
edition = {1st},
abstract = {From the Publisher:Michael Sipser's philosophy in writing this book is simple: make the subject interesting and relevant, and the students will learn. His emphasis on unifying computer science theory - rather than offering a collection of low-level details - sets the book apart, as do his intuitive explanations. Throughout the book, Sipser - a noted authority on the theory of computation - builds students' knowledge of conceptual tools used in computer science, the aesthetic sense they need to create elegant systems, and the ability to think through problems on their own. INTRODUCTION TO THE THEORY OF COMPUTATION provides a mathematical treatment of computation theory grounded in theorems and proofs. Proofs are presented with a "proof idea" component to reveal the concepts underpinning the formalism. Algorithms are presented using prose instead of pseudocode to focus attention on the algorithms themselves, rather than on specific computational models. Topic coverage, terminology, and order of presentation are traditional for an upper-level course in computer science theory. Users of the Preliminary Edition (now out of print) will be interested to note several new chapters on complexity theory: Chapter 8 on space complexity; Chapter 9 on provable intractability, and Chapter 10 on advanced topics, including approximation algorithms, alternation, interactive proof systems, cryptography, and parallel computing.}
}
@book{2021Ebbinghaus,
abstract = {This textbook introduces first-order logic and its role in the foundations of mathematics by examining fundamental questions. What is a mathematical proof? How can mathematical proofs be justified? Are there limitations to provability? To what extent can machines carry out mathematical proofs? In answering these questions, this textbook explores the capabilities and limitations of algorithms and proof methods in mathematics and computer science. The chapters are carefully organized, featuring complete proofs and numerous examples throughout. Beginning with motivating examples, the book goes on to present the syntax and semantics of first-order logic. After providing a sequent calculus for this logic, a Henkin-type proof of the completeness theorem is given. These introductory chapters prepare the reader for the advanced topics that follow, such as Gödel's Incompleteness Theorems, Trakhtenbrot's undecidability theorem, Lindström's theorems on the maximality of first-order logic, and results linking logic with automata theory. This new edition features many modernizations, as well as two additional important results: The decidability of Presburger arithmetic, and the decidability of the weak monadic theory of the successor function. Mathematical Logic is ideal for students beginning their studies in logic and the foundations of mathematics. Although the primary audience for this textbook will be graduate students or advanced undergraduates in mathematics or computer science, in fact the book has few formal prerequisites. It demands of the reader only mathematical maturity and experience with basic abstract structures, such as those encountered in discrete mathematics or algebra.},
author = {Ebbinghaus, Heinz-Dieter},
address = {Cham, Switzerland},
edition = {Third edition.},
isbn = {9783030738396},
keywords = {Logic, Symbolic and mathematical},
language = {eng},
publisher = {Springer},
series = {Graduate texts in mathematics},
title = {Mathematical logic},
year = {2021},
}
@inbook{2012benari,
author = {Ben-Ari, M.},
address = {London},
edition = {3rd ed.},
isbn = {9781447141297},
keywords = {Logic, Symbolic and mathematical},
language = {eng},
publisher = {Springer},
title = {Mathematical logic for computer science},
year = {2012},
chapter={7},
}
@inproceedings{Dreben1979TheDP,
  title={The decision problem: Solvable classes of quantificational formulas},
  author={Burton Dreben and Warren D. Goldfarb},
  year={1979}
}
@article{lewis1980complexity,
  title={{Complexity results for classes of quantificational formulas}},
  author={Lewis, Harry R},
  journal={Journal of Computer and System Sciences},
  volume={21},
  number={3},
  pages={317--353},
  year={1980},
  publisher={Elsevier}
}
@techreport{demoura2008deciding,
author = {de Moura, Leonardo and Piskac, Ruzica and Bjørner, Nikolaj},
title = {{Deciding Effectively Propositional Logic using DPLL and Substitution Sets}},
year = {2008},
month = {August},
abstract = {We introduce a DPLL calculus that is a decision procedure for the Bernays-Schoenfinkel class, also known as EPR. Our calculus allows combining techniques for efficient propositional search with data-structures, such as Binary Decision Diagrams, that can efficiently and succinctly encode finite sets of substitutions and operations on these. In the calculus, clauses comprise of a sequence of literals together with a finite set of substitutions; truth assignments are also represented using substitution sets. The calculus works directly at the level of sets, and admits performing simultaneous constraint propagation and decisions, resulting in potentially exponential speedups over existing approaches.},
publisher = {Springer-Verlag},
url = {https://www.microsoft.com/en-us/research/publication/deciding-effectively-propositional-logic-using-dpll-and-substitution-sets/},
pages = {21},
number = {MSR-TR-2008-104},
}
@InProceedings{2016merzmanysorted,
author="Merz, Stephan
and Vanzetto, Hern{\'a}n",
editor="Butler, Michael
and Schewe, Klaus-Dieter
and Mashkoor, Atif
and Biro, Miklos",
title="Encoding TLA+ into Many-Sorted First-Order Logic",
booktitle="Abstract State Machines, Alloy, B, TLA, VDM, and Z",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="54--69",
isbn="978-3-319-33600-8"
}
@InProceedings{2007decidablefragmentsmanysorted,
author="Abadi, Aharon
and Rabinovich, Alexander
and Sagiv, Mooly",
editor="Dershowitz, Nachum
and Voronkov, Andrei",
title="Decidable Fragments of Many-Sorted Logic",
booktitle="Logic for Programming, Artificial Intelligence, and Reasoning",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="17--31",
abstract="We investigate the possibility of developing a decidable logic which allows expressing a large variety of real world specifications. The idea is to define a decidable subset of many-sorted (typed) first- order logic. The motivation is that types simplify the complexity of mixed quantifiers when they quantify over different types. We noticed that many real world verification problems can be formalized by quantifying over different types in such a way that the relations between types remain simple.",
isbn="978-3-540-75560-9"
}
@InProceedings{2020ivymultimodal,
author="McMillan, Kenneth L.
and Padon, Oded",
editor="Lahiri, Shuvendu K.
and Wang, Chao",
title="Ivy: A Multi-modal Verification Tool for Distributed Algorithms",
booktitle="Computer Aided Verification",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="190--202",
abstract="Ivy is a multi-modal verification tool for correct design and implementation of distributed protocols and algorithms, supporting modular specification, implementation and proof. Ivy supports proving safety and liveness properties of parameterized and infinite-state systems via three modes: deductive verification using an SMT solver, abstraction and model checking, and manual proofs using natural deduction. It supports light-weight formal methods via compositional specification-based testing and bounded model checking. Ivy can extract executable distributed programs by translation to efficient C++ code. It is designed to support decidable automated reasoning, to improve proof stability and to provide transparency in the case of proof failures. For this purpose, it presents concrete finite counterexamples, automatically audits proofs for decidability of verification conditions, and provides modular hiding of theories.",
isbn="978-3-030-53291-8"
}
@InProceedings{2009completeinstant,
author="Ge, Yeting
and de Moura, Leonardo",
editor="Bouajjani, Ahmed
and Maler, Oded",
title="Complete Instantiation for Quantified Formulas in Satisfiabiliby Modulo Theories",
booktitle="Computer Aided Verification",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="306--320",
abstract="Quantifier reasoning in Satisfiability Modulo Theories (SMT) is a long-standing challenge. The practical method employed in modern SMT solvers is to instantiate quantified formulas based on heuristics, which is not refutationally complete even for pure first-order logic. We present several decidable fragments of first order logic modulo theories. We show how to construct models for satisfiable formulas in these fragments. For richer undecidable fragments, we discuss conditions under which our procedure is refutationally complete. We also describe useful heuristics based on model checking for prioritizing or avoiding instantiations.",
isbn="978-3-642-02658-4"
}
@misc{2014manysortedlogic,
title="Many-sorted logic",
author="Jouko Vaananen",
year="2014",
url={http://www.math.helsinki.fi/logic/opetus/msl/ILLC_MSL_2014.1.pdf},
howpublished={\url{http://www.math.helsinki.fi/logic/opetus/msl/ILLC_MSL_2014.1.pdf}},
}
@article{1986kozen,
author = {Apt, K R and Kozen, D C},
title = {Limits for Automatic Verification of Finite-State Concurrent Systems},
year = {1986},
issue_date = {May 30,1986},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {22},
number = {6},
issn = {0020-0190},
url = {https://doi.org/10.1016/0020-0190(86)90071-2},
doi = {10.1016/0020-0190(86)90071-2},
journal = {Inf. Process. Lett.},
month = {may},
pages = {307–309},
numpages = {3}
}
@article{1997clarkenetwork,
author = {Clarke, E. M. and Grumberg, O. and Jha, S.},
title = {Verifying Parameterized Networks},
year = {1997},
issue_date = {Sept. 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {5},
issn = {0164-0925},
url = {https://doi.org/10.1145/265943.265960},
doi = {10.1145/265943.265960},
abstract = {This article describes a technique based on network grammars and abstraction to verify families of state-transition systems. The family of state-transition systems is represented by a context-free network grammar. Using the structure of the network grammar our technique constructs a process invariant that simulates all the state-transition systems in the family. A novel idea introduced in this article is the use of regular languages to express state properties. We have implemented our techniques and verified two nontrivial examples.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {sep},
pages = {726–750},
numpages = {25},
keywords = {parameterized systems, temporal logic, model checking, process invariants}
}
@book{libkin2004elements,
  title={Elements of finite model theory},
  author={Libkin, Leonid},
  volume={41},
  year={2004},
  publisher={Springer}
}
@Inbook{Kroening2016,
author="Kroening, Daniel
and Strichman, Ofer",
title="Quantified Formulas",
bookTitle="Decision Procedures: An Algorithmic Point of View",
year="2016",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="199--227",
abstract="Quantification allows us to specify the extent of validity of a predicate, the domain in which the predicate should hold. The syntactic element used in the logic for specifying quantification is called a quantifier.",
isbn="978-3-662-50497-0",
doi="10.1007/978-3-662-50497-0_9",
url="https://doi.org/10.1007/978-3-662-50497-0_9"
}
@inproceedings{1977cousot,
author = {Cousot, Patrick and Cousot, Radhia},
title = {Abstract Interpretation: A Unified Lattice Model for Static Analysis of Programs by Construction or Approximation of Fixpoints},
year = {1977},
isbn = {9781450373500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/512950.512973},
doi = {10.1145/512950.512973},
abstract = {A program denotes computations in some universe of objects. Abstract interpretation of programs consists in using that denotation to describe computations in another universe of abstract objects, so that the results of abstract execution give some information on the actual computations. An intuitive example (which we borrow from Sintzoff [72]) is the rule of signs. The text -1515 * 17 may be understood to denote computations on the abstract universe {(+), (-), (±)} where the semantics of arithmetic operators is defined by the rule of signs. The abstract execution -1515 * 17 → -(+) * (+) → (-) * (+) → (-), proves that -1515 * 17 is a negative number. Abstract interpretation is concerned by a particular underlying structure of the usual universe of computations (the sign, in our example). It gives a summary of some facets of the actual executions of a program. In general this summary is simple to obtain but inaccurate (e.g. -1515 + 17 → -(+) + (+) → (-) + (+) → (±)). Despite its fundamentally incomplete results abstract interpretation allows the programmer or the compiler to answer questions which do not need full knowledge of program executions or which tolerate an imprecise answer, (e.g. partial correctness proofs of programs ignoring the termination problems, type checking, program optimizations which are not carried in the absence of certainty about their feasibility, …).},
booktitle = {Proceedings of the 4th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
pages = {238–252},
numpages = {15},
location = {Los Angeles, California},
series = {POPL '77}
}

@Inbook{Dams2018,
author="Dams, Dennis
and Grumberg, Orna",
editor="Clarke, Edmund M.
and Henzinger, Thomas A.
and Veith, Helmut
and Bloem, Roderick",
title="Abstraction and Abstraction Refinement",
bookTitle="Handbook of Model Checking",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="385--419",
abstract="Abstraction, in the context of model checking, is aimed at reducing the state space of the system by omitting details that are irrelevant to the property being verified. Many successful approaches to the ``state explosion problem,'' some of them described in other chapters, can be seen as abstractions. In this chapter, several notions of abstraction are considered in a uniform setting. Different such notions lead to a variety of preservation results that establish which kind of temporal properties may be verified via an abstracted system. We first define the needed background on simulation and bisimulation relations and their logic preservation. We then present the abstraction that is currently most widely used in practice: existential abstraction, which preserves universal fragments of branching-time logics. We give examples of such abstractions: localization reduction for hardware and predicate abstraction for software. We then proceed to stronger abstractions which preserve full branching-time logics. We introduce Kripke Modal Transition Systems and modal simulation, and show logic preservation. We close the chapter with a review of the presented results in the light of the notion of completeness.",
isbn="978-3-319-10575-8",
doi="10.1007/978-3-319-10575-8_13",
url="https://doi.org/10.1007/978-3-319-10575-8_13"
}
@Inbook{Clarke2018ch1,
author="Clarke, Edmund M.
and Henzinger, Thomas A.
and Veith, Helmut",
editor="Clarke, Edmund M.
and Henzinger, Thomas A.
and Veith, Helmut
and Bloem, Roderick",
title="Introduction to Model Checking",
bookTitle="Handbook of Model Checking",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="1--26",
abstract="Model checking is a computer-assisted method for the analysis of dynamical systems that can be modeled by state-transition systems. Drawing from research traditions in mathematical logic, programming languages, hardware design, and theoretical computer science, model checking is now widely used for the verification of hardware and software in industry. This chapter is an introduction and short survey of model checking. The chapter aims to motivate and link the individual chapters of the handbook, and to provide context for readers who are not familiar with model checking.",
isbn="978-3-319-10575-8",
doi="10.1007/978-3-319-10575-8_1",
url="https://doi.org/10.1007/978-3-319-10575-8_1"
}

@inproceedings{2003abswithoutcex,
author = {McMillan, Kenneth L. and Amla, Nina},
title = {Automatic Abstraction without Counterexamples},
year = {2003},
isbn = {3540008985},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A method of automatic abstraction is presented that uses proofs of unsatisfiability derived from SAT-based bounded model checking as a guide to choosing an abstraction for unbounded model checking. Unlike earlier methods, this approach is not based on analysis of abstract counterexamples. The performance of this approach on benchmarks derived from microprocessor verification indicates that SAT solvers are quite effective in eliminating logic that is not relevant to a given property. Moreover, benchmark results suggest that when bounded model checking successfully terminates, and the problem is unsatisfiable, the number of state variables in the proof of unsatisfiability tends to be small. In almost all cases tested, when bounded model checking succeeded, unbounded model checking of the resulting abstraction also succeeded.},
booktitle = {Proceedings of the 9th International Conference on Tools and Algorithms for the Construction and Analysis of Systems},
pages = {2–17},
numpages = {16},
location = {Warsaw, Poland},
series = {TACAS'03}
}
@article{94mcabs,
author = {Clarke, Edmund M. and Grumberg, Orna and Long, David E.},
title = {Model Checking and Abstraction},
year = {1994},
issue_date = {Sept. 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {5},
issn = {0164-0925},
url = {https://doi.org/10.1145/186025.186051},
doi = {10.1145/186025.186051},
abstract = {We describe a method for using abstraction to reduce the complexity of temporal-logic model checking. Using techniques similar to those involved in abstract interpretation, we construct an abstract model of a program without ever examining the corresponding unabstracted model. We show how this abstract model can be used to verify properties of the original program. We have implemented a system based on these techniques, and we demonstrate their practicality using a number of examples, including a program representing a pipelined ALU circuit with over 101300 states.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {sep},
pages = {1512–1542},
numpages = {31},
keywords = {temporal logic, abstract interpretation, model checking, binary decision diagrams (BDDs)}
}
@InProceedings{2003satinterp,
author="McMillan, K. L.",
editor="Hunt, Warren A.
and Somenzi, Fabio",
title="Interpolation and SAT-Based Model Checking",
booktitle="Computer Aided Verification",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--13",
abstract="We consider a fully SAT-based method of unbounded symbolic model checking based on computing Craig interpolants. In benchmark studies using a set of large industrial circuit verification instances, this method is greatly more efficient than BDD-based symbolic model checking, and compares favorably to some recent SAT-based model checking methods on positive instances.",
isbn="978-3-540-45069-6"
}
@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group}
}
@book{graham1989concrete,
author = {Graham, Ronald L. and Knuth, Donald E. and Patashnik, Oren},
title = {{Concrete Mathematics: A Foundation for Computer Science}},
year = {1994},
isbn = {0201558025},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
address = {USA},
edition = {2nd},
abstract = {From the Publisher: This book introduces the mathematics that supports advanced computer programming and the analysis of algorithms. The primary aim of its well-known authors is to provide a solid and relevant base of mathematical skills - the skills needed to solve complex problems, to evaluate horrendous sums, and to discover subtle patterns in data. It is an indispensable text and reference not only for computer scientists - the authors themselves rely heavily on it! - but for serious users of mathematics in virtually every discipline. Concrete Mathematics is a blending of CONtinuous and disCRETE mathematics. "More concretely," the authors explain, "it is the controlled manipulation of mathematical formulas, using a collection of techniques for solving problems." The subject matter is primarily an expansion of the Mathematical Preliminaries section in Knuth's classic Art of Computer Programming, but the style of presentation is more leisurely, and individual topics are covered more deeply. Several new topics have been added, and the most significant ideas have been traced to their historical roots. The book includes more than 500 exercises, divided into six categories. Complete answers are provided for all exercises, except research problems, making the book particularly valuable for self-study. Major topics include: Sums Recurrences Integer functions Elementary number theory Binomial coefficients Generating functions Discrete probability Asymptotic methods This second edition includes important new material about mechanical summation. In response to the widespread use ofthe first edition as a reference book, the bibliography and index have also been expanded, and additional nontrivial improvements can be found on almost every page. Readers will appreciate the informal style of Concrete Mathematics. Particularly enjoyable are the marginal graffiti contributed by students who have taken courses based on this material. The authors want to convey not only the importance of the techniques presented, but some of the fun in learning and using them.}
}
@incollection{Doerr_2019,
	doi = {10.1007/978-3-030-29414-4_1},
	url = {https://doi.org/10.1007%2F978-3-030-29414-4_1},
	year = 2019,
	month = {nov},
	publisher = {Springer International Publishing},
	pages = {1--87},
	author = {Benjamin Doerr},
	title = {Probabilistic Tools for the Analysis of Randomized Optimization Heuristics},
	booktitle = {Natural Computing Series}
}
@book{2011fourthcomporgdesign,
author = {Patterson, David A. and Hennessy, John L.},
title = {Computer Organization and Design, Revised Fourth Edition, Fourth Edition: The Hardware/Software Interface},
year = {2011},
isbn = {0123747503},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
edition = {4th},
abstract = {This Fourth Revised Edition of Computer Organization and Design includes a complete set of updated and new exercises, along with improvements and changes suggested by instructors and students. Focusing on the revolutionary change taking place in industry today--the switch from uniprocessor to multicore microprocessors--this classic textbook has a modern and up-to-date focus on parallelism in all its forms. Examples highlighting multicore and GPU processor designs are supported with performance and benchmarking data. As with previous editions, a MIPS processor is the core used to present the fundamentals of hardware technologies, assembly language, computer arithmetic, pipelining, memory hierarchies and I/O. Sections on the ARM and x86 architectures are also included.The companion CD provides a toolkit of simulators and compilers along with tutorials for using them, as well as advanced content for further study and a search utility for finding content on the CD and in the printed text. For the convenience of readers who have purchased an ebook edition or who may have misplaced the CD-ROM, all CD content is available as a download at bit.ly/nFXcLqThis Revised Fourth Edition of Computer Organization and Design has been updated with new exercises and improvements throughout suggested by instructors teaching from the bookCovers the revolutionary change from sequential to parallel computing, with a chapter on parallelism and sections in every chapter highlighting parallel hardware and software topicsIncludes an appendix by the Chief Scientist and the Director of Architecture of NVIDIA covering the emergence and importance of the modern GPU, describing in detail for the first time the highly parallel, highly multithreaded multiprocessor optimized for visual computing}
}
@article{manna1980deductive,
  title={A deductive approach to program synthesis},
  author={Manna, Zohar and Waldinger, Richard},
  journal={ACM Transactions on Programming Languages and Systems (TOPLAS)},
  volume={2},
  number={1},
  pages={90--121},
  year={1980},
  publisher={ACM New York, NY, USA}
}
@InProceedings{1981clarkemerson,
author="Clarke, Edmund M.
and Emerson, E. Allen",
editor="Kozen, Dexter",
title="Design and synthesis of synchronization skeletons using branching time temporal logic",
booktitle="Logics of Programs",
year="1982",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="52--71",
abstract="We have shown that it is possible to automatically synthesize the synchronization skeleton of a concurrent program from a Temporal Logic specification. We believe that this approach may in the long run turn out to be quite practical. Since synchronization skeletons are, in general, quite small, the potentially exponential behavior of our algorithm need not be an insurmountable obstacle. Much additional research will be needed, however, to make the approach feasible in practice.",
isbn="978-3-540-39047-3"
}
@article{1984mannawolper,
author = {Manna, Zohar and Wolper, Pierre},
title = {{Synthesis of Communicating Processes from Temporal Logic Specifications}},
year = {1984},
issue_date = {Jan. 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
issn = {0164-0925},
url = {https://doi.org/10.1145/357233.357237},
doi = {10.1145/357233.357237},
journal = {ACM Trans. Program. Lang. Syst.},
month = {jan},
pages = {68–93},
numpages = {26}
}
@inproceedings{1981benari,
author = {Ben-Ari, Mordechai and Manna, Zohar and Pnueli, Amir},
title = {The Temporal Logic of Branching Time},
year = {1981},
isbn = {089791029X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/567532.567551},
doi = {10.1145/567532.567551},
abstract = {A temporal language and system are presented which are based on branching time structure. By the introduction of symmetrically dual sets of temporal operators, it is possible to discuss properties which hold either along one path or along all paths. Consequently it is possible to express in this system all the properties that were previously expressible in linear time or branching time systems. We present an exponential decision procedure for satisfiability in the language based on tableaux methods, and a complete deduction system. As associated temporal semantics is illustrated for both structured and graph representation of programs.},
booktitle = {Proceedings of the 8th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {164–176},
numpages = {13},
location = {Williamsburg, Virginia},
series = {POPL '81}
}
@article{2001attie,
author = {Attie, Paul C. and Emerson, E. Allen},
title = {Synthesis of Concurrent Programs for an Atomic Read/Write Model of Computation},
year = {2001},
issue_date = {March 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {2},
issn = {0164-0925},
url = {https://doi.org/10.1145/383043.383044},
doi = {10.1145/383043.383044},
abstract = {Methods for mechanically synthesizing concurrent programs for temporal logic specifications have been proposed by Emerson and Clarke and by Manna and Wolper. An important advantage of these synthesis methods is that they obviate the need to manually compose a program and manually construct a proof of its correctness. A serious drawback of these methods in practice, however, is that they produce concurrent programs for models of computation that are often unrealistic, involving highly centralized system architecture (Manna and Wolper), processes with global information about the system state (Emerson and Clarke), or reactive modules that can read all of their inputs in one atomic step (Anuchitanukul and Manna, and Pnueli and Rosner). Even simple synchronization protocols based on atomic read/write primitives such as Peterson's solution to the mutual exclusion problem have remained outside the scope of practical mechanical synthesis methods. In this paper, we show how to mechanically synthesize in more realistic computational models solutions to synchronization problems. We illustrate the method by synthesizing Peterson's solution to the mutual exclusion problem.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {mar},
pages = {187–242},
numpages = {56},
keywords = {program synthesis, temporal logic, atomic registers, specification, concurrent programs}
}
@article{1986clarkeemerson,
author = {Clarke, E. M. and Emerson, E. A. and Sistla, A. P.},
title = {Automatic Verification of Finite-State Concurrent Systems Using Temporal Logic Specifications},
year = {1986},
issue_date = {April 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {0164-0925},
url = {https://doi.org/10.1145/5397.5399},
doi = {10.1145/5397.5399},
abstract = {We give an efficient procedure for verifying that a finite-state concurrent system meets a specification expressed in a (propositional, branching-time) temporal logic. Our algorithm has complexity linear in both the size of the specification and the size of the global state graph for the concurrent system. We also show how this approach can be adapted to handle fairness. We argue that our technique can provide a practical alternative to manual proof construction or use of a mechanical theorem prover for verifying many finite-state concurrent systems. Experimental results show that state machines with several hundred states can be checked in a matter of seconds.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {apr},
pages = {244–263},
numpages = {20}
}
@inproceedings{1983wolpervardi,
author = {Wolper, Pierre and Vardi, Moshe Y. and Sistla, A. Prasad},
title = {Reasoning about Infinite Computation Paths},
year = {1983},
isbn = {0818605081},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SFCS.1983.51},
doi = {10.1109/SFCS.1983.51},
abstract = {We investigate extensions of temporal logic by finite automata on infinite words. There are three different types of acceptance conditions (finite, looping and repeating) that one can give for these finite automata. This gives rise to three different logics. It turns out, however. that these logics have the same expressive power but differ in the complexity of their decision problem. We also investigate the addition of alternation and show that it does not increase the complexity of the decision problem.},
booktitle = {Proceedings of the 24th Annual Symposium on Foundations of Computer Science},
pages = {185–194},
numpages = {10},
series = {SFCS '83}
}
@inproceedings{1985pnuelilich,
author = {Lichtenstein, Orna and Pnueli, Amir},
title = {Checking That Finite State Concurrent Programs Satisfy Their Linear Specification},
year = {1985},
isbn = {0897911474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/318593.318622},
doi = {10.1145/318593.318622},
abstract = {We present an algorithm for checking satisfiability of a linear time temporal logic formula over a finite state concurrent program. The running time of the algorithm is exponential in the size of the formula but linear in the size of the checked program. The algorithm yields also a formal proof in case the formula is valid over the program. The algorithm has four versions that check satisfiability by unrestricted, impartial, just and fair computations of the given program.},
booktitle = {Proceedings of the 12th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
pages = {97–107},
numpages = {11},
location = {New Orleans, Louisiana, USA},
series = {POPL '85}
}
@article{BIERE2002160,
title = {Liveness Checking as Safety Checking},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {66},
number = {2},
pages = {160-177},
year = {2002},
note = {FMICS'02, 7th International ERCIM Workshop in Formal Methods for Industrial Critical Systems (ICALP 2002 Satellite Workshop)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/S1571-0661(04)80410-9},
url = {https://www.sciencedirect.com/science/article/pii/S1571066104804109},
author = {Armin Biere and Cyrille Artho and Viktor Schuppan},
abstract = {Temporal logic is widely used for specifying hardware and software systems. Typically two types of properties are distinguished, safety and liveness properties. While safety can easily be checked by reachability analysis, and many efficient checkers for safety properties exist, more sophisticated algorithms have always been considered to be necessary for checking liveness. In this paper we describe an efficient translation of liveness checking problems into safety checking problems. A counter example is detected by saving a previously visited state in an additional state recording component and checking a loop closing condition. The approach handles fairness and thus extends to full LTL.}
}
@article{1985sistlaclarke,
author = {Sistla, A. P. and Clarke, E. M.},
title = {The Complexity of Propositional Linear Temporal Logics},
year = {1985},
issue_date = {July 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {3},
issn = {0004-5411},
url = {https://doi.org/10.1145/3828.3837},
doi = {10.1145/3828.3837},
abstract = {The complexity of satisfiability and determination of truth in a particular finite structure are considered for different propositional linear temporal logics. It is shown that these problems are NP-complete for the logic with F and are PSPACE-complete for the logics with F, X, with U, with U, S, X operators and for the extended logic with regular operators given by Wolper.},
journal = {J. ACM},
month = {jul},
pages = {733–749},
numpages = {17}
}
@inproceedings{1999castropbft,
author = {Castro, Miguel and Liskov, Barbara},
title = {Practical Byzantine Fault Tolerance},
year = {1999},
isbn = {1880446391},
publisher = {USENIX Association},
address = {USA},
booktitle = {Proceedings of the Third Symposium on Operating Systems Design and Implementation},
pages = {173–186},
numpages = {14},
location = {New Orleans, Louisiana, USA},
series = {OSDI '99}
}
@inproceedings{2011lamport,
author = {Lamport, Leslie},
title = {Byzantizing Paxos by Refinement},
year = {2011},
isbn = {9783642240997},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We derive a 3f +1 process Byzantine Paxos consensus algorithm by Byzantizing a variant of the ordinary Paxos algorithm--that is, by having 2f+1 nonfaulty processes emulate the ordinary Paxos algorithm despite the presence of f malicious processes. We have written a formal, machine-checked proof that the Byzantized algorithm implements the ordinary Paxos consensus algorithm under a suitable refinement mapping.},
booktitle = {Proceedings of the 25th International Conference on Distributed Computing},
pages = {211–224},
numpages = {14},
location = {Rome, Italy},
series = {DISC'11}
}
@article{1978rivestcrypto,
author = {Rivest, R. L. and Shamir, A. and Adleman, L.},
title = {A Method for Obtaining Digital Signatures and Public-Key Cryptosystems},
year = {1978},
issue_date = {Feb. 1978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/359340.359342},
doi = {10.1145/359340.359342},
abstract = {An encryption method is presented with the novel property that publicly revealing an encryption key does not thereby reveal the corresponding decryption key. This has two important consequences: (1) Couriers or other secure means are not needed to transmit keys, since a message can be enciphered using an encryption key publicly revealed by the intented recipient. Only he can decipher the message, since only he knows the corresponding decryption key. (2) A message can be “signed” using a privately held decryption key. Anyone can verify this signature using the corresponding publicly revealed encryption key. Signatures cannot be forged, and a signer cannot later deny the validity of his signature. This has obvious applications in “electronic mail” and “electronic funds transfer” systems. A message is encrypted by representing it as a number M, raising M to a publicly specified power e, and then taking the remainder when the result is divided by the publicly specified product, n, of two large secret primer numbers p and q. Decryption is similar; only a different, secret, power d is used, where e * d ≡ 1(mod (p - 1) * (q - 1)). The security of the system rests in part on the difficulty of factoring the published divisor, n.},
journal = {Commun. ACM},
month = {feb},
pages = {120–126},
numpages = {7},
keywords = {authentication, factorization, cryptography, electronic mail, public-key cryptosystems, privacy, message-passing, security, electronic funds transfer, digital signatures, prime number}
}
@article{1982lamportshostak,
author = {Lamport, Leslie and Shostak, Robert and Pease, Marshall},
title = {{The Byzantine Generals Problem}},
year = {1982},
issue_date = {July 1982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
issn = {0164-0925},
url = {https://doi.org/10.1145/357172.357176},
doi = {10.1145/357172.357176},
journal = {ACM Trans. Program. Lang. Syst.},
month = {jul},
pages = {382–401},
numpages = {20}
}
@article{1980peasereaching,
author = {Pease, M. and Shostak, R. and Lamport, L.},
title = {Reaching Agreement in the Presence of Faults},
year = {1980},
issue_date = {April 1980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {2},
issn = {0004-5411},
url = {https://doi.org/10.1145/322186.322188},
doi = {10.1145/322186.322188},
abstract = {The problem addressed here concerns a set of isolated processors, some unknown subset of which may be faulty, that communicate only by means of two-party messages. Each nonfaulty processor has a private value of information that must be communicated to each other nonfaulty processor. Nonfaulty processors always communicate honestly, whereas faulty processors may lie. The problem is to devise an algorithm in which processors communicate their own values and relay values received from others that allows each nonfaulty processor to infer a value for each other processor. The value inferred for a nonfaulty processor must be that processor's private value, and the value inferred for a faulty one must be consistent with the corresponding value inferred by each other nonfaulty processor.It is shown that the problem is solvable for, and only for, n ≥ 3m + 1, where m is the number of faulty processors and n is the total number. It is also shown that if faulty processors can refuse to pass on information but cannot falsely relay information, the problem is solvable for arbitrary n ≥ m ≥ 0. This weaker assumption can be approximated in practice using cryptographic methods.},
journal = {J. ACM},
month = {apr},
pages = {228–234},
numpages = {7}
}
@ARTICLE{1978sift,  
author={Wensley, J.H. and Lamport, L. and Goldberg, J. and Green, M.W. and Levitt, K.N. and Melliar-Smith, P.M. and Shostak, R.E. and Weinstock, C.B.},  
journal={Proceedings of the IEEE},   
title={SIFT: Design and analysis of a fault-tolerant computer for aircraft control},   
year={1978},  
volume={66},  
number={10},  
pages={1240-1255},  
doi={10.1109/PROC.1978.11114}}
@inproceedings{2018abrahamsyncbyz,
author = {Abraham, Ittai and Devadas, Srinivas and Dolev, Danny and Nayak, Kartik and Ren, Ling},
title = {Synchronous Byzantine Agreement with Expected O(1) Rounds, Expected Communication, and Optimal Resilience},
year = {2019},
isbn = {978-3-030-32100-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-32101-7_20},
doi = {10.1007/978-3-030-32101-7_20},
abstract = {We present new protocols for Byzantine agreement in the synchronous and authenticated setting, tolerating the optimal number of f faults among parties. Our protocols achieve an expected O(1) round complexity and an expected communication complexity. The exact round complexity in expectation is 10 for a static adversary and 16 for a strongly rushing adaptive adversary. For comparison, previous protocols in the same setting require expected 29 rounds.},
booktitle = {Financial Cryptography and Data Security: 23rd International Conference, FC 2019, Frigate Bay, St. Kitts and Nevis, February 18–22, 2019, Revised Selected Papers},
pages = {320–334},
numpages = {15},
location = {St. Kitts, Saint Kitts and Nevis}
}
@book{2008principlemc,
author = {Baier, Christel and Katoen, Joost-Pieter},
year = {2008},
month = {01},
pages = {},
title = {Principles of Model Checking},
volume = {26202649},
isbn = {978-0-262-02649-9}
}
@inproceedings{1969waldingersynthprow,
author = {Waldinger, Richard J. and Lee, Richard C. T.},
title = {PROW: A Step toward Automatic Program Writing},
year = {1969},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {This paper Describes a program, called "PROW", which writes programs PROW accepts the specification of the program in the language of predicate calculus, decides the algorithm for the program and then produces a LISP program which is an implementation of the algorithm. Since the construction of the algorithm is obtained by formal theorem-proving techniques, the programs that PROW writes are free from logical errors and do not have to be debugged The user of PROW can make PROW write programs in languages other than LISP by modifying the part of PROW that translates an algorithm to a LISP program. Thus PROW can be modified to write programs in any language In the end of this paper, it is shown that PROW can also be used as a question-answering program},
booktitle = {Proceedings of the 1st International Joint Conference on Artificial Intelligence},
pages = {241–252},
numpages = {12},
location = {Washington, DC},
series = {IJCAI'69}
}
@inproceedings{1989pnuelirosner,
author = {Pnueli, A. and Rosner, R.},
title = {On the Synthesis of a Reactive Module},
year = {1989},
isbn = {0897912942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75277.75293},
doi = {10.1145/75277.75293},
abstract = {We consider the synthesis of a reactive module with input x and output y, which is specified by the linear temporal formula @@@@(x, y). We show that there exists a program satisfying @@@@ iff the branching time formula (∀x) (∃y) A@@@@(x, y) is valid over all tree models. For the restricted case that all variables range over finite domains, the validity problem is decidable, and we present an algorithm for constructing the program whenever it exists. The algorithm is based on a new procedure for checking the emptiness of Rabin automata on infinite trees in time exponential in the number of pairs, but only polynomial in the number of states. This leads to a synthesis algorithm whose complexity is double exponential in the length of the given specification.},
booktitle = {Proceedings of the 16th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {179–190},
numpages = {12},
location = {Austin, Texas, USA},
series = {POPL '89}
}
@article{1975dijkstrawp,
author = {Dijkstra, Edsger W.},
title = {Guarded Commands, Nondeterminacy and Formal Derivation of Programs},
year = {1975},
issue_date = {Aug. 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {8},
issn = {0001-0782},
url = {https://doi.org/10.1145/360933.360975},
doi = {10.1145/360933.360975},
abstract = {So-called “guarded commands” are introduced as a building block for alternative and repetitive constructs that allow nondeterministic program components for which at least the activity evoked, but possibly even the final state, is not necessarily uniquely determined by the initial state. For the formal derivation of programs expressed in terms of these constructs, a calculus will be be shown.},
journal = {Commun. ACM},
month = {aug},
pages = {453–457},
numpages = {5},
keywords = {sequencing primitives, correctness proof, programming languages, program semantics, derivation of programs, programming methodology, termination, repetition, nondeterminancy, case-construction, programming language semantics}
}
@article{1991waitfreesync,
author = {Herlihy, Maurice},
title = {Wait-Free Synchronization},
year = {1991},
issue_date = {Jan. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0164-0925},
url = {https://doi.org/10.1145/114005.102808},
doi = {10.1145/114005.102808},
abstract = {A wait-free implementation of a concurrent data object is one that guarantees that any process can complete any operation in a finite number of steps, regardless of the execution speeds of the other processes. The problem of constructing a wait-free implementation of one data object from another lies at the heart of much recent work in concurrent algorithms, concurrent data structures, and multiprocessor architectures. First, we introduce a simple and general technique, based on reduction to a concensus protocol, for proving statements of the form, “there is no wait-free implementation of X by Y.” We derive a hierarchy of objects such that no object at one level has a wait-free implementation in terms of objects at lower levels. In particular, we show that atomic read/write registers, which have been the focus of much recent attention, are at the bottom of the hierarchy: thay cannot be used to construct wait-free implementations of many simple and familiar data types. Moreover, classical synchronization primitives such astest\&set and fetch\&add, while more powerful than read and write, are also computationally weak, as are the standard message-passing primitives. Second, nevertheless, we show that there do exist simple universal objects from which one can construct a wait-free implementation of any sequential object.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {jan},
pages = {124–149},
numpages = {26},
keywords = {linearization, wait-free synchronization}
}
@article{1990aspnesherlihy,
author = {Aspnes, James and Herlihy, M.},
title = {Fast Randomized Consensus Using Shared Memory},
year = {1990},
issue_date = {Sep. 1990},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {11},
number = {3},
issn = {0196-6774},
url = {https://doi.org/10.1016/0196-6774(90)90021-6},
doi = {10.1016/0196-6774(90)90021-6},
journal = {J. Algorithms},
month = {sep},
pages = {441–461},
numpages = {21}
}
@article{2002bierelivenessassafety,
title = {Liveness Checking as Safety Checking},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {66},
number = {2},
pages = {160-177},
year = {2002},
note = {FMICS'02, 7th International ERCIM Workshop in Formal Methods for Industrial Critical Systems (ICALP 2002 Satellite Workshop)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/S1571-0661(04)80410-9},
url = {https://www.sciencedirect.com/science/article/pii/S1571066104804109},
author = {Armin Biere and Cyrille Artho and Viktor Schuppan},
abstract = {Temporal logic is widely used for specifying hardware and software systems. Typically two types of properties are distinguished, safety and liveness properties. While safety can easily be checked by reachability analysis, and many efficient checkers for safety properties exist, more sophisticated algorithms have always been considered to be necessary for checking liveness. In this paper we describe an efficient translation of liveness checking problems into safety checking problems. A counter example is detected by saving a previously visited state in an additional state recording component and checking a loop closing condition. The approach handles fairness and thus extends to full LTL.}
}
@inproceedings{bradley2011sat,
  title={SAT-based model checking without unrolling},
  author={Bradley, Aaron R},
  booktitle={International Workshop on Verification, Model Checking, and Abstract Interpretation},
  pages={70--87},
  year={2011},
  organization={Springer}
}
@inproceedings{2007bradleymannasafety,
author = {Bradley, Aaron R. and Manna, Zohar},
title = {Checking Safety by Inductive Generalization of Counterexamples to Induction},
year = {2007},
isbn = {0769530230},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Scaling verification to large circuits requires some form of abstraction relative to the asserted property. We describe a safety analysis of finite-state systems that generalizes from counterexamples to the inductiveness of the safety specification to inductive invariants. It thus abstracts the system's state space relative to the property. The analysis either strengthens a safety specification to be inductive or discovers a counterexample to its correctness. The analysis is easily made parallel. We provide experimental data showing how the analysis time decreases with the number of processes on several hard problems.},
booktitle = {Proceedings of the Formal Methods in Computer Aided Design},
pages = {173–180},
numpages = {8},
series = {FMCAD '07}
}
@article{lamport2006fast,
author = {Lamport, Leslie},
title = {Fast Paxos},
year = {2006},
month = {October},
abstract = {The Paxos consensus algorithm of [122] requires two message delays between when the leader proposes a value and when other processes learn that the value has been chosen. Since inventing Paxos, I had thought that this was the optimal message delay. However, sometime in late 2001 I realized that in most systems that use consensus, values aren't picked out of the air by the system itself; instead, they come from clients. When one counts the message from the client, Paxos requires three message delays. This led me to wonder whether consensus in two message delays, including the client's message, was in fact possible. I proved the lower-bound result announced in [143] that an algorithm that can make progress despite f faults and can achieve consensus in two message delays despite e faults requires more than 2e+f processes. The proof of that result led me pretty quickly to the Fast Paxos algorithm described here. Fast Paxos generalizes the classic Paxos consensus algorithm. It can switch between learning in two or three message delays depending on how many processes are working. More precisely, it can achieve learning in two message delays only in the absence of concurrent conflicting proposals, which [153] shows is the best a general algorithm can do.},
url = {https://www.microsoft.com/en-us/research/publication/fast-paxos/},
pages = {79-103},
journal = {Distributed Computing},
volume = {19},
edition = {Distributed Computing},
}
@inproceedings{2013epaxosmoraru,
author = {Moraru, Iulian and Andersen, David G. and Kaminsky, Michael},
title = {There is More Consensus in Egalitarian Parliaments},
year = {2013},
isbn = {9781450323888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2517349.2517350},
doi = {10.1145/2517349.2517350},
abstract = {This paper describes the design and implementation of Egalitarian Paxos (EPaxos), a new distributed consensus algorithm based on Paxos. EPaxos achieves three goals: (1) optimal commit latency in the wide-area when tolerating one and two failures, under realistic conditions; (2) uniform load balancing across all replicas (thus achieving high throughput); and (3) graceful performance degradation when replicas are slow or crash.Egalitarian Paxos is to our knowledge the first protocol to achieve the previously stated goals efficiently---that is, requiring only a simple majority of replicas to be non-faulty, using a number of messages linear in the number of replicas to choose a command, and committing commands after just one communication round (one round trip) in the common case or after at most two rounds in any case. We prove Egalitarian Paxos's properties theoretically and demonstrate its advantages empirically through an implementation running on Amazon EC2.},
booktitle = {Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles},
pages = {358–372},
numpages = {15},
location = {Farminton, Pennsylvania},
series = {SOSP '13}
}
@inproceedings{2011zab,
author = {Junqueira, Flavio P. and Reed, Benjamin C. and Serafini, Marco},
title = {Zab: High-Performance Broadcast for Primary-Backup Systems},
year = {2011},
isbn = {9781424492329},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/DSN.2011.5958223},
doi = {10.1109/DSN.2011.5958223},
abstract = {Zab is a crash-recovery atomic broadcast algorithm we designed for the ZooKeeper coordination service. ZooKeeper implements a primary-backup scheme in which a primary process executes clients operations and uses Zab to propagate the corresponding incremental state changes to backup processes1. Due the dependence of an incremental state change on the sequence of changes previously generated, Zab must guarantee that if it delivers a given state change, then all other changes it depends upon must be delivered first. Since primaries may crash, Zab must satisfy this requirement despite crashes of primaries.},
booktitle = {Proceedings of the 2011 IEEE/IFIP 41st International Conference on Dependable Systems\&Networks},
pages = {245–256},
numpages = {12},
series = {DSN '11}
}
@inproceedings{2008zabsimple,
author = {Reed, Benjamin and Junqueira, Flavio P.},
title = {A Simple Totally Ordered Broadcast Protocol},
year = {2008},
isbn = {9781605582962},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1529974.1529978},
doi = {10.1145/1529974.1529978},
abstract = {This is a short overview of a totally ordered broadcast protocol used by ZooKeeper, called Zab. It is conceptually easy to understand, is easy to implement, and gives high performance. In this paper we present the requirements ZooKeeper makes on Zab, we show how the protocol is used, and we give an overview of how the protocol works.},
booktitle = {Proceedings of the 2nd Workshop on Large-Scale Distributed Systems and Middleware},
articleno = {2},
numpages = {6},
location = {Yorktown Heights, New York, USA},
series = {LADIS '08}
}

@article{nakamoto2009bitcoin,
  abstract = {A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone.},
  added-at = {2022-06-15T13:43:05.000+0200},
  author = {Nakamoto, Satoshi},
  biburl = {https://www.bibsonomy.org/bibtex/2974d35fdb27dea57296ed2245556aa18/daniel_grm9},
  interhash = {423c2cdff70ba0cd0bca55ebb164d770},
  intrahash = {974d35fdb27dea57296ed2245556aa18},
  keywords = {itsecseminar},
  month = may,
  timestamp = {2022-06-15T13:43:05.000+0200},
  title = {Bitcoin: A Peer-to-Peer Electronic Cash System},
  url = {http://www.bitcoin.org/bitcoin.pdf},
  year = 2009
}
@article{Buterin2013,
  Title                    = {{Ethereum White Paper: A Next Generation Smart Contract \& Decentralized Application Platform}},
  Author                   = {Vitalik Buterin},
  Year                     = {2014},
  url                      = {https://ethereum.org/whitepaper},
  howpublished             = {https://ethereum.org/whitepaper}
}
@inproceedings{2016towncrier,
author = {Zhang, Fan and Cecchetti, Ethan and Croman, Kyle and Juels, Ari and Shi, Elaine},
title = {Town Crier: An Authenticated Data Feed for Smart Contracts},
year = {2016},
isbn = {9781450341394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976749.2978326},
doi = {10.1145/2976749.2978326},
abstract = {Smart contracts are programs that execute autonomously on blockchains. Their key envisioned uses (e.g. financial instruments) require them to consume data from outside the blockchain (e.g. stock quotes). Trustworthy data feeds that support a broad range of data requests will thus be critical to smart contract ecosystems.We present an authenticated data feed system called Town Crier (TC). TC acts as a bridge between smart contracts and existing web sites, which are already commonly trusted for non-blockchain applications. It combines a blockchain front end with a trusted hardware back end to scrape HTTPS-enabled websites and serve source-authenticated data to relying smart contracts.TC also supports confidentiality. It enables private data requests with encrypted parameters. Additionally, in a generalization that executes smart-contract logic within TC, the system permits secure use of user credentials to scrape access-controlled online data sources.We describe TC's design principles and architecture and report on an implementation that uses Intel's recently introduced Software Guard Extensions (SGX) to furnish data to the Ethereum smart contract system. We formally model TC and define and prove its basic security properties in the Universal Composibility (UC) framework. Our results include definitions and techniques of general interest relating to resource consumption (Ethereum's "gas" fee system) and TCB minimization. We also report on experiments with three example applications.We plan to launch TC soon as an online public service.},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
pages = {270–282},
numpages = {13},
keywords = {authenticated data feeds, bitcoin, ethereum, intel SGX, smart contracts, trusted hardware},
location = {Vienna, Austria},
series = {CCS '16}
}
@article{breidenbach2021chainlink,
  title={Chainlink 2.0: Next steps in the evolution of decentralized oracle networks},
  author={Breidenbach, Lorenz and Cachin, Christian and Chan, Benedict and Coventry, Alex and Ellis, Steve and Juels, Ari and Koushanfar, Farinaz and Miller, Andrew and Magauran, Brendan and Moroz, Daniel and others},
  journal={Chainlink Labs},
  volume={1},
  pages={1--136},
  year={2021}
}
@article{lamport2001paxos,
  title={Paxos made simple},
  author={Lamport, Leslie},
  journal={ACM SIGACT News (Distributed Computing Column) 32, 4 (Whole Number 121, December 2001)},
  pages={51--58},
  year={2001}
}
@inproceedings{lamport2009vertical,
  title={Vertical paxos and primary-backup replication},
  author={Lamport, Leslie and Malkhi, Dahlia and Zhou, Lidong},
  booktitle={Proceedings of the 28th ACM symposium on Principles of distributed computing},
  pages={312--313},
  year={2009}
}
@inproceedings{2001leinoflanagan,
author = {Flanagan, Cormac and Leino, K. Rustan M.},
title = {{Houdini, an Annotation Assistant for ESC/Java}},
year = {2001},
isbn = {3540417915},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A static program checker that performs modular checking can check one program module for errors without needing to analyze the entire program. Modular checking requires that each module be accompanied by annotations that specify the module. To help reduce the cost of writing specifications, this paper presents Houdini, an annotation assistant for the modular checker ESC/Java. To infer suitable ESC/Java annotations for a given program, Houdini generates a large number of candidate annotations and uses ESC/Java to verify or refute each of these annotations. The paper describes the design, implementation, and preliminary evaluation of Houdini.},
booktitle = {Proceedings of the International Symposium of Formal Methods Europe on Formal Methods for Increasing Software Productivity},
pages = {500–517},
numpages = {18},
series = {FME '01}
}
@book{mannasafetybook,
author = {Manna, Zohar and Pnueli, Amir},
title = {Temporal Verification of Reactive Systems: Safety},
year = {1995},
isbn = {0387944591},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}
@inproceedings{2005symbolicpor,
author = {Bhattacharya, Ritwik and German, Steven and Gopalakrishnan, Ganesh},
year = {2005},
month = {10},
pages = {332-335},
title = {A Symbolic Partial Order Reduction Algorithm for Rule Based Transition Systems},
volume = {3725},
isbn = {978-3-540-29105-3},
doi = {10.1007/11560548_25}
}
@inproceedings{2012calvin,
author = {Thomson, Alexander and Diamond, Thaddeus and Weng, Shu-Chun and Ren, Kun and Shao, Philip and Abadi, Daniel J.},
title = {Calvin: fast distributed transactions for partitioned database systems},
year = {2012},
isbn = {9781450312479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2213836.2213838},
doi = {10.1145/2213836.2213838},
abstract = {Many distributed storage systems achieve high data access throughput via partitioning and replication, each system with its own advantages and tradeoffs. In order to achieve high scalability, however, today's systems generally reduce transactional support, disallowing single transactions from spanning multiple partitions. Calvin is a practical transaction scheduling and data replication layer that uses a deterministic ordering guarantee to significantly reduce the normally prohibitive contention costs associated with distributed transactions. Unlike previous deterministic database system prototypes, Calvin supports disk-based storage, scales near-linearly on a cluster of commodity machines, and has no single point of failure. By replicating transaction inputs rather than effects, Calvin is also able to support multiple consistency levels---including Paxos-based strong consistency across geographically distant replicas---at no cost to transactional throughput.},
booktitle = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},
pages = {1–12},
numpages = {12},
keywords = {determinism, distributed database systems, replication, transaction processing},
location = {Scottsdale, Arizona, USA},
series = {SIGMOD '12}
}
@book{1986concurrency,
author = {Bernstein, Philip A and Hadzilacos, Vassos and Goodman, Nathan},
title = {Concurrency control and recovery in database systems},
year = {1986},
isbn = {0201107155},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
address = {USA}
}
@article{2012spanner,
  title={{Spanner: Google's Globally Distributed Database}},
  author={Corbett, James C and Dean, Jeffrey and Epstein, Michael and Fikes, Andrew and Frost, Christopher and Furman, Jeffrey John and Ghemawat, Sanjay and Gubarev, Andrey and Heiser, Christopher and Hochschild, Peter and others},
  journal={ACM Transactions on Computer Systems (TOCS)},
  volume={31},
  number={3},
  pages={1--22},
  year={2012},
  publisher={ACM New York, NY, USA}
}
@inproceedings{2011walter,
author = {Sovran, Yair and Power, Russell and Aguilera, Marcos K. and Li, Jinyang},
title = {Transactional storage for geo-replicated systems},
year = {2011},
isbn = {9781450309776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2043556.2043592},
doi = {10.1145/2043556.2043592},
abstract = {We describe the design and implementation of Walter, a key-value store that supports transactions and replicates data across distant sites. A key feature behind Walter is a new property called Parallel Snapshot Isolation (PSI). PSI allows Walter to replicate data asynchronously, while providing strong guarantees within each site. PSI precludes write-write conflicts, so that developers need not worry about conflict-resolution logic. To prevent write-write conflicts and implement PSI, Walter uses two new and simple techniques: preferred sites and counting sets. We use Walter to build a social networking application and port a Twitter-like application.},
booktitle = {Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles},
pages = {385–400},
numpages = {16},
keywords = {transactions, parallel snapshot isolation, key-value store, geo-distributed systems, distributed storage, asynchronous replication},
location = {Cascais, Portugal},
series = {SOSP '11}
}
@inproceedings{2013mdcc,
author = {Kraska, Tim and Pang, Gene and Franklin, Michael J. and Madden, Samuel and Fekete, Alan},
title = {MDCC: multi-data center consistency},
year = {2013},
isbn = {9781450319942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2465351.2465363},
doi = {10.1145/2465351.2465363},
abstract = {Replicating data across multiple data centers allows using data closer to the client, reducing latency for applications, and increases the availability in the event of a data center failure. MDCC (Multi-Data Center Consistency) is an optimistic commit protocol for geo-replicated transactions, that does not require a master or static partitioning, and is strongly consistent at a cost similar to eventually consistent protocols. MDCC takes advantage of Generalized Paxos for transaction processing and exploits commutative updates with value constraints in a quorum-based system. Our experiments show that MDCC outperforms existing synchronous transactional replication protocols, such as Megastore, by requiring only a single message round-trip in the normal operational case independent of the master-location and by scaling linearly with the number of machines as long as transaction conflict rates permit.},
booktitle = {Proceedings of the 8th ACM European Conference on Computer Systems},
pages = {113–126},
numpages = {14},
location = {Prague, Czech Republic},
series = {EuroSys '13}
}
@inproceedings{2015tapir,
author = {Zhang, Irene and Sharma, Naveen Kr. and Szekeres, Adriana and Krishnamurthy, Arvind and Ports, Dan R. K.},
title = {Building consistent transactions with inconsistent replication},
year = {2015},
isbn = {9781450338349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2815400.2815404},
doi = {10.1145/2815400.2815404},
abstract = {Application programmers increasingly prefer distributed storage systems with strong consistency and distributed transactions (e.g., Google's Spanner) for their strong guarantees and ease of use. Unfortunately, existing transactional storage systems are expensive to use -- in part because they require costly replication protocols, like Paxos, for fault tolerance. In this paper, we present a new approach that makes transactional storage systems more affordable: we eliminate consistency from the replication protocol while still providing distributed transactions with strong consistency to applications.We present TAPIR -- the Transactional Application Protocol for Inconsistent Replication -- the first transaction protocol to use a novel replication protocol, called inconsistent replication, that provides fault tolerance without consistency. By enforcing strong consistency only in the transaction protocol, TAPIR can commit transactions in a single round-trip and order distributed transactions without centralized coordination. We demonstrate the use of TAPIR in a transactional key-value store, TAPIR-KV. Compared to conventional systems, TAPIR-KV provides better latency and throughput.},
booktitle = {Proceedings of the 25th Symposium on Operating Systems Principles},
pages = {263–278},
numpages = {16},
location = {Monterey, California},
series = {SOSP '15}
}
@article{2020elle,
author = {Kingsbury, Kyle and Alvaro, Peter},
title = {Elle: inferring isolation anomalies from experimental observations},
year = {2020},
issue_date = {November 2020},
publisher = {VLDB Endowment},
volume = {14},
number = {3},
issn = {2150-8097},
url = {https://doi.org/10.14778/3430915.3430918},
doi = {10.14778/3430915.3430918},
abstract = {Users who care about their data store it in databases, which (at least in principle) guarantee some form of transactional isolation. However, experience shows that many databases do not provide the isolation guarantees they claim. With the recent proliferation of new distributed databases, demand has grown for checkers that can, by generating client workloads and injecting faults, produce anomalies that witness a violation of a stated guarantee. An ideal checker would be sound (no false positives), efficient (polynomial in history length and concurrency), effective (finding violations in real databases), general (analyzing many patterns of transactions), and informative (justifying the presence of an anomaly with understandable counterexamples). Sadly, we are aware of no checkers that satisfy these goals.We present Elle: a novel checker which infers an Adya-style dependency graph between client-observed transactions. It does so by carefully selecting database objects and operations when generating histories, so as to ensure that the results of database reads reveal information about their version history. Elle can detect every anomaly in Adya et al's formalism (except for predicates), discriminate between them, and provide concise explanations of each. This paper makes the following contributions: we present Elle, demonstrate its soundness over specific datatypes, measure its efficiency against the current state of the art, and give evidence of its effectiveness via a case study of four real databases.},
journal = {Proc. VLDB Endow.},
month = nov,
pages = {268–280},
numpages = {13}
}
@inproceedings{2017viper,
author = {Zhang, Jian and Ji, Ye and Mu, Shuai and Tan, Cheng},
title = {Viper: A Fast Snapshot Isolation Checker},
year = {2023},
isbn = {9781450394871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3552326.3567492},
doi = {10.1145/3552326.3567492},
abstract = {Snapshot isolation (SI) is supported by most commercial databases and is widely used by applications. However, checking SI today---given a set of transactions, checking if they obey SI---is either slow or gives up soundness.We present viper, an SI checker that is sound, complete, and fast. Viper checks black-box databases and hence is transparent to both users and databases. To be fast, viper introduces BC-polygraphs, a new representation of transaction dependencies. A BC-polygraph is acyclic iff transactions are SI, a theorem that we prove. Viper also introduces heuristic pruning, an optimization to accelerate checking SI by leveraging common knowledge of real-world database implementations. Besides vanilla SI, viper supports major SI variants including Strong SI, Generalized SI, and Strong Session SI. Our experiments show that given the same time budget, viper improves over baselines by 15\texttimes{} in the workload sizes being checked.},
booktitle = {Proceedings of the Eighteenth European Conference on Computer Systems},
pages = {654–671},
numpages = {18},
keywords = {databases, verification},
location = {Rome, Italy},
series = {EuroSys '23}
}
@inproceedings{2020cockroachdb,
author = {Taft, Rebecca and Sharif, Irfan and Matei, Andrei and VanBenschoten, Nathan and Lewis, Jordan and Grieger, Tobias and Niemi, Kai and Woods, Andy and Birzin, Anne and Poss, Raphael and Bardea, Paul and Ranade, Amruta and Darnell, Ben and Gruneir, Bram and Jaffray, Justin and Zhang, Lucy and Mattis, Peter},
title = {CockroachDB: The Resilient Geo-Distributed SQL Database},
year = {2020},
isbn = {9781450367356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318464.3386134},
doi = {10.1145/3318464.3386134},
abstract = {We live in an increasingly interconnected world, with many organizations operating across countries or even continents. To serve their global user base, organizations are replacing their legacy DBMSs with cloud-based systems capable of scaling OLTP workloads to millions of users. CockroachDB is a scalable SQL DBMS that was built from the ground up to support these global OLTP workloads while maintaining high availability and strong consistency. Just like its namesake, CockroachDB is resilient to disasters through replication and automatic recovery mechanisms. This paper presents the design of CockroachDB and its novel transaction model that supports consistent geo-distributed transactions on commodity hardware. We describe how CockroachDB replicates and distributes data to achieve fault tolerance and high performance, as well as how its distributed SQL layer automatically scales with the size of the database cluster while providing the standard SQL interface that users expect. Finally, we present a comprehensive performance evaluation and share a couple of case studies of CockroachDB users. We conclude by describing lessons learned while building CockroachDB over the last five years.},
booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
pages = {1493–1509},
numpages = {17},
location = {Portland, OR, USA},
series = {SIGMOD '20}
}
@article{2012postgresql,
author = {Ports, Dan R. K. and Grittner, Kevin},
title = {Serializable snapshot isolation in PostgreSQL},
year = {2012},
issue_date = {August 2012},
publisher = {VLDB Endowment},
volume = {5},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/2367502.2367523},
doi = {10.14778/2367502.2367523},
abstract = {This paper describes our experience implementing PostgreSQL's new serializable isolation level. It is based on the recently-developed Serializable Snapshot Isolation (SSI) technique. This is the first implementation of SSI in a production database release as well as the first in a database that did not previously have a lock-based serializable isolation level. We reflect on our experience and describe how we overcame some of the resulting challenges, including the implementation of a new lock manager, a technique for ensuring memory usage is bounded, and integration with other PostgreSQL features. We also introduce an extension to SSI that improves performance for read-only transactions. We evaluate PostgreSQL's serializable isolation level using several benchmarks and show that it achieves performance only slightly below that of snapshot isolation, and significantly outperforms the traditional two-phase locking approach on read-intensive workloads.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {1850–1861},
numpages = {12}
}
@inproceedings{10.1145/1294261.1294278,
author = {Aguilera, Marcos K. and Merchant, Arif and Shah, Mehul and Veitch, Alistair and Karamanolis, Christos},
title = {Sinfonia: a new paradigm for building scalable distributed systems},
year = {2007},
isbn = {9781595935915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1294261.1294278},
doi = {10.1145/1294261.1294278},
abstract = {We propose a new paradigm for building scalable distributed systems. Our approach does not require dealing with message-passing protocols -- a major complication in existing distributed systems. Instead, developers just design and manipulate data structures within our service called Sinfonia. Sinfonia keeps data for applications on a set of memory nodes, each exporting a linear address space. At the core of Sinfonia is a novel minitransaction primitive that enables efficient and consistent access to data, while hiding the complexities that arise from concurrency and failures. Using Sinfonia, we implemented two very different and complex applications in a few months: a cluster file system and a group communication service. Our implementations perform well and scale to hundreds of machines.},
booktitle = {Proceedings of Twenty-First ACM SIGOPS Symposium on Operating Systems Principles},
pages = {159–174},
numpages = {16},
keywords = {two-phase commit, transactions, shared memory, scalability, fault tolerance, distributed systems},
location = {Stevenson, Washington, USA},
series = {SOSP '07}
}

@article{2007sinfonia,
author = {Aguilera, Marcos K. and Merchant, Arif and Shah, Mehul and Veitch, Alistair and Karamanolis, Christos},
title = {Sinfonia: a new paradigm for building scalable distributed systems},
year = {2007},
issue_date = {December 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {6},
issn = {0163-5980},
url = {https://doi.org/10.1145/1323293.1294278},
doi = {10.1145/1323293.1294278},
abstract = {We propose a new paradigm for building scalable distributed systems. Our approach does not require dealing with message-passing protocols -- a major complication in existing distributed systems. Instead, developers just design and manipulate data structures within our service called Sinfonia. Sinfonia keeps data for applications on a set of memory nodes, each exporting a linear address space. At the core of Sinfonia is a novel minitransaction primitive that enables efficient and consistent access to data, while hiding the complexities that arise from concurrency and failures. Using Sinfonia, we implemented two very different and complex applications in a few months: a cluster file system and a group communication service. Our implementations perform well and scale to hundreds of machines.},
journal = {SIGOPS Oper. Syst. Rev.},
month = oct,
pages = {159–174},
numpages = {16},
keywords = {two-phase commit, transactions, shared memory, scalability, fault tolerance, distributed systems}
}
@inproceedings {2023chardonnay,
author = {Tamer Eldeeb and Xincheng Xie and Philip A. Bernstein and Asaf Cidon and Junfeng Yang},
title = {Chardonnay: Fast and General Datacenter Transactions for {On-Disk} Databases},
booktitle = {17th USENIX Symposium on Operating Systems Design and Implementation (OSDI 23)},
year = {2023},
isbn = {978-1-939133-34-2},
address = {Boston, MA},
pages = {343--360},
url = {https://www.usenix.org/conference/osdi23/presentation/eldeeb},
publisher = {USENIX Association},
month = jul
}
@inproceedings{2010percolator,
author = {Peng, Daniel and Dabek, Frank},
title = {Large-scale incremental processing using distributed transactions and notifications},
year = {2010},
publisher = {USENIX Association},
address = {USA},
abstract = {Updating an index of the web as documents are crawled requires continuously transforming a large repository of existing documents as new documents arrive. This task is one example of a class of data processing tasks that transform a large repository of data via small, independent mutations. These tasks lie in a gap between the capabilities of existing infrastructure. Databases do not meet the storage or throughput requirements of these tasks: Google's indexing system stores tens of petabytes of data and processes billions of updates per day on thousands of machines. MapReduce and other batch-processing systems cannot process small updates individually as they rely on creating large batches for efficiency.We have built Percolator, a system for incrementally processing updates to a large data set, and deployed it to create the Google web search index. By replacing a batch-based indexing system with an indexing system based on incremental processing using Percolator, we process the same number of documents per day, while reducing the average age of documents in Google search results by 50\%.},
booktitle = {Proceedings of the 9th USENIX Conference on Operating Systems Design and Implementation},
pages = {251–264},
numpages = {14},
location = {Vancouver, BC, Canada},
series = {OSDI'10}
}
@inproceedings{2011megastore,
  author = {Baker, Jason and Bond, Chris and Corbett, James C. and Furman, JJ and Khorlin, Andrey and Larson, James and Leon, Jean-Michel and Li, Yawei and Lloyd, Alexander and Yushprakh, Vadim},
  title = {Megastore: Providing Scalable, Highly Available Storage for Interactive Services},
  booktitle = {Conference on Innovative Data Systems Research (CIDR)},
  year = {2011},
  pages = {223--234},
  location = {Asilomar, California},
  abstract = {Megastore is a storage system developed to meet the requirements of today's interactive online services. Megastore blends the scalability of a NoSQL datastore with the convenience of a traditional RDBMS in a novel way, and provides both strong consistency guarantees and high availability. We provide fully serializable ACID semantics within fine-grained partitions of data. This partitioning allows us to synchronously replicate each write across a wide area network with reasonable latency and support seamless failover between datacenters.}
}
@inproceedings{2024unanimous2pc,
author = {Jensen, Chris and Howard, Heidi and Katsarakis, Antonios and Mortier, Richard},
title = {Unanimous 2PC: Fault-tolerant Distributed Transactions Can be Fast and Simple},
year = {2024},
isbn = {9798400705441},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3642976.3653035},
doi = {10.1145/3642976.3653035},
abstract = {Distributed transactional datastores are pivotal in supporting the needs of modern applications and services. Datastores rely on distributed transactional protocols to tolerate faults while also aiming for strong consistency and high performance. State-of-the-art transactional protocols, such as FaRM, provide a lock-free execution phase, thus improving performance and simplifying recovery. However, these protocols often come with lengthy and complicated commit phases, requiring multiple round-trips to commit a transaction (or additional replicas). This completely contrasts with the simplicity and efficiency of the traditional two-phase commit (2PC) protocol, which can commit a transaction after a single round-trip, albeit lacking fault tolerance.To address the limitations of both approaches, we introduce U2PC, a novel 2PC variant that combines simplicity, efficiency, and fault tolerance. U2PC frugally replicates data (f + 1) times to tolerate up to f faults with strong consistency. It offers a single round-trip commit after unanimous responses of all replicas of the involved shards and ensures safe recovery via an extra "pre-abort" round before aborting a transaction. Our verification in TLA+ confirms that U2PC achieves strict serializability and recovers safely. In short, U2PC ensures fault tolerance, optimizes performance for common scenarios, and offers uniform transaction handling.},
booktitle = {Proceedings of the 11th Workshop on Principles and Practice of Consistency for Distributed Data},
pages = {44–57},
numpages = {14},
keywords = {distributed transactions, 2PC, FastPaxos},
location = {Athens, Greece},
series = {PaPoC '24}
}
@article{2016baqueroclocks,
author = {Baquero, Carlos and Pregui\c{c}a, Nuno},
title = {Why Logical Clocks are Easy: Sometimes all you need is the right language.},
year = {2016},
issue_date = {January-February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {1},
issn = {1542-7730},
url = {https://doi.org/10.1145/2898442.2917756},
doi = {10.1145/2898442.2917756},
abstract = {Any computing system can be described as executing sequences of actions, with an action being any relevant change in the state of the system. For example, reading a file to memory, modifying the contents of the file in memory, or writing the new contents to the file are relevant actions for a text editor. In a distributed system, actions execute in multiple locations; in this context, actions are often called events. Examples of events in distributed systems include sending or receiving messages, or changing some state in a node. Not all events are related, but some events can cause and influence how other, later events occur. For example, a reply to a received mail message is influenced by that message, and maybe by prior messages received.},
journal = {Queue},
month = feb,
pages = {53–69},
numpages = {17}
}
@article{fidge1988timestamps,
  added-at = {2012-01-14T13:04:26.000+0100},
  author = {Fidge, C. J.},
  biburl = {https://www.bibsonomy.org/bibtex/2cc829c490de6ff6203758943b4d3ca84/nosebrain},
  description = {Timestamps in message-passing systems that preserve the partial ordering | Mendeley},
  interhash = {27bbdd2f31ec6e29b97770b3e017cddc},
  intrahash = {cc829c490de6ff6203758943b4d3ca84},
  journal = {Proceedings of the 11th Australian Computer Science Conference},
  keywords = {clock vector},
  number = 1,
  pages = {56–66},
  timestamp = {2012-01-14T13:04:26.000+0100},
  title = {Timestamps in message-passing systems that preserve the partial ordering},
  url = {http://sky.scitech.qut.edu.au/~fidgec/Publications/fidge88a.pdf},
  volume = 10,
  year = 1988
}
@inproceedings{2017seeingcrooks,
author = {Crooks, Natacha and Pu, Youer and Alvisi, Lorenzo and Clement, Allen},
title = {Seeing is Believing: A Client-Centric Specification of Database Isolation},
year = {2017},
isbn = {9781450349925},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3087801.3087802},
doi = {10.1145/3087801.3087802},
abstract = {This paper introduces the first state-based formalization of isolation guarantees. Our approach is premised on a simple observation: applications view storage systems as black-boxes that transition through a series of states, a subset of which are observed by applications. Defining isolation guarantees in terms of these states frees definitions from implementation-specific assumptions. It makes immediately clear what anomalies, if any, applications can expect to observe, thus bridging the gap that exists today between how isolation guarantees are defined and how they are perceived. The clarity that results from definitions based on client-observable states brings forth several benefits. First, it allows us to easily compare the guarantees of distinct, but semantically close, isolation guarantees. We find that several well-known guarantees, previously thought to be distinct, are in fact equivalent, and that many previously incomparable flavors of snapshot isolation can be organized in a clean hierarchy. Second, freeing definitions from implementation-specific artefacts can suggest more efficient implementations of the same isolation guarantee. We show how a client-centric implementation of parallel snapshot isolation can be more resilient to slowdown cascades, a common phenomenon in large-scale datacenters.},
booktitle = {Proceedings of the ACM Symposium on Principles of Distributed Computing},
pages = {73–82},
numpages = {10},
keywords = {acid, cloud storage, concurrency control, consistency, database, distributed storage, distributed systems, eventual consistency, isolation, serializability, transactions, weak consistency},
location = {Washington, DC, USA},
series = {PODC '17}
}
